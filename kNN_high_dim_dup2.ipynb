{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d12f6ef",
   "metadata": {},
   "source": [
    "# Illustrate how kNN works in high dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c20eb",
   "metadata": {},
   "source": [
    "The idea here is that if you look at the data in pre DL world high dimensions will make most algoritms struggle. But post DL, embeddings are much easier for classical algorithms to work with. Let's take kNN. When it will get a bunch of text raw as binds, it will have a very hard time to figure out groups and to make the groups meaningful. On the other hand, if we put the chunks through an embedding, the kNN should work just fine. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51249642",
   "metadata": {},
   "source": [
    "I want to test this assumption and simply visualize two sets of texts. First, I need to have something to work with. Let's just get a blog post and a source code chunk using the resursive chunker to examples 500 chars long. We will make a bag of word and compare how it performs, then we make embeddings out of text run kNN on that.v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b885095",
   "metadata": {},
   "source": [
    "The results illustrate the concept clearly:\n",
    "- **Raw text (no feature engineering)**: Pure noise with random accuracy (30% for characters, 50% for tokens)\n",
    "- **Bag-of-words with one-hot encoding**: Struggles with high dimensionality (600+ features â†’ 70% accuracy), but improves significantly in lower dimensions (100, 50 features â†’ 95% accuracy)\n",
    "- **Embeddings**: Despite having **3,000 dimensions**, achieves perfect 100% accuracy\n",
    "\n",
    "This demonstrates that curse of dimensionality does not apply to embeddings and kNN works fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e2828",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I want to setup GITHUB to upload this code, help me\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "I'll help you set up GitHub to upload your code. Let me start by checking what files you currently have in your working directory:\n",
    "\n",
    "```python\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "list(Path('.').glob('*'))\n",
    "```\n",
    "\n",
    "Run this first so we can see what we're working with, then I'll help you create the necessary Git setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d660e2",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "nextsteps\r\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let me help you with the next steps for setting up GitHub. First, let's check if you have git installed and configured:\n",
    "\n",
    "```python\n",
    "!git --version\n",
    "```\n",
    "\n",
    "Then check your git config:\n",
    "\n",
    "```python\n",
    "!git config --list\n",
    "```\n",
    "\n",
    "Run these so we can see your current git setup status."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5236d431",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I need to create a project in github\r\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "To create a new GitHub project, you have two options:\n",
    "\n",
    "**Option 1: Create repository on GitHub website first (recommended)**\n",
    "1. Go to https://github.com/new\n",
    "2. Create a new repository with a name (e.g., \"knn-embeddings-demo\")\n",
    "3. Don't initialize with README (we'll push existing code)\n",
    "4. Copy the repository URL\n",
    "\n",
    "Then run:\n",
    "```python\n",
    "!git init\n",
    "!git add .\n",
    "!git commit -m \"Initial commit: kNN embeddings demonstration\"\n",
    "!git branch -M main\n",
    "!git remote add origin YOUR_REPO_URL\n",
    "!git push -u origin main\n",
    "```\n",
    "\n",
    "**Option 2: Create from command line using GitHub CLI**\n",
    "\n",
    "First check if you have GitHub CLI:\n",
    "```python\n",
    "!gh --version\n",
    "```\n",
    "\n",
    "Run this to see if you have `gh` installed. If you do, I can show you how to create the repo directly from here.\n",
    "\n",
    "Which approach would you prefer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4fc02",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "option 2\r\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's check if you have GitHub CLI installed:\n",
    "\n",
    "```python\n",
    "!gh --version\n",
    "```\n",
    "\n",
    "Run this first so we can proceed with creating the repository from the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e23891a",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "gh version 2.83.1 (2025-11-13)\r\n",
    "https://github.com/cli/cli/releases/tag/v2.83.1\r\n",
    "next step\r\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Now let's authenticate with GitHub (if you haven't already) and create the repository:\n",
    "\n",
    "```python\n",
    "!gh auth status\n",
    "```\n",
    "\n",
    "Run this to check if you're logged in. If not authenticated, you'll need to run `gh auth login` to log in first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c107fdd",
   "metadata": {
    "time_run": "2025-12-03T06:37:20.849401+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6n"
     ]
    }
   ],
   "source": [
    "!gh auth status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20cfd89",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "What is next step\r\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! You're authenticated. Now let's initialize git and create the GitHub repository:\n",
    "\n",
    "```python\n",
    "!git init\n",
    "!git add .\n",
    "!gh repo create knn-embeddings-demo --public --source=. --remote=origin --push\n",
    "```\n",
    "\n",
    "This will create a new public repository called \"knn-embeddings-demo\" and push your code. You can change the name or use `--private` instead of `--public` if you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35054238",
   "metadata": {
    "time_run": "2025-12-03T06:13:32.356572+00:00"
   },
   "outputs": [],
   "source": [
    "!git init\n",
    "!git add .\n",
    "!gh repo create knn-embeddings-demo --public --source=. --remote=origin --push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d143e664",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "How to fix this resource not accesible by token\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "The token doesn't have the right permissions. Let's create the repo on GitHub's website first, then push to it:\n",
    "\n",
    "```python\n",
    "!gh auth refresh -s repo\n",
    "```\n",
    "\n",
    "This will refresh your token with repository creation permissions. You'll need to follow the authentication flow in your browser.\n",
    "\n",
    "Alternatively, if that doesn't work, create the repo manually:\n",
    "\n",
    "1. Go to https://github.com/new\n",
    "2. Name it \"knn-embeddings-demo\"\n",
    "3. Don't initialize with anything\n",
    "4. Create it\n",
    "\n",
    "Then run:\n",
    "```python\n",
    "!git remote add origin https://github.com/niminet/knn-embeddings-demo.git\n",
    "!git branch -M main\n",
    "!git commit -m \"Initial commit: kNN embeddings demonstration\"\n",
    "!git push -u origin main\n",
    "```\n",
    "\n",
    "Which approach do you want to try?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44abcfd3",
   "metadata": {
    "time_run": "2025-12-03T06:16:17.721496+00:00"
   },
   "outputs": [],
   "source": [
    "!gh auth refresh -s repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c06de",
   "metadata": {
    "time_run": "2025-12-03T06:17:39.820650+00:00"
   },
   "outputs": [],
   "source": [
    "!git remote add origin https://github.com/niminet/knn-embeddings-demo.git\n",
    "!git branch -M main\n",
    "!git commit -m \"Initial commit: kNN embeddings demonstration\"\n",
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c80a68c",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "check the error above and help fix\r\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "The remote is pointing to the wrong repository. Let's fix it:\n",
    "\n",
    "```python\n",
    "!git remote remove origin\n",
    "!git remote add origin https://github.com/niminet/knn-embeddings-demo.git\n",
    "!git add .\n",
    "!git commit -m \"Initial commit: kNN embeddings demonstration\"\n",
    "!git push -u origin main\n",
    "```\n",
    "\n",
    "But first, you need to create the repository at https://github.com/new with the name \"knn-embeddings-demo\". Have you created it on GitHub yet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f127f3d",
   "metadata": {
    "time_run": "2025-12-03T06:20:04.491979+00:00"
   },
   "outputs": [],
   "source": [
    "!git remote remove origin\n",
    "!git remote add origin https://github.com/niminet/knn-embeddings-demo.git\n",
    "!git add .\n",
    "!git commit -m \"Initial commit: kNN embeddings demonstration\"\n",
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ead4f3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "permission error , I used token to login - what is the issue\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "The token needs to be included in the URL for HTTPS push. Let's update the remote URL with your token:\n",
    "\n",
    "```python\n",
    "!git remote set-url origin https://YOUR_TOKEN@github.com/niminet/knn-embeddings-demo.git\n",
    "```\n",
    "\n",
    "Replace `YOUR_TOKEN` with your GitHub personal access token. \n",
    "\n",
    "Or, use the GitHub CLI to push instead:\n",
    "\n",
    "```python\n",
    "!gh repo view niminet/knn-embeddings-demo\n",
    "```\n",
    "\n",
    "First run this to verify the repo exists. If it does, then:\n",
    "\n",
    "```python\n",
    "!gh repo set-default niminet/knn-embeddings-demo\n",
    "!git push -u origin main\n",
    "```\n",
    "\n",
    "The `gh` CLI should handle authentication automatically since you're already logged in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8714622f",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Is there better method to have token in file and use for all my github PR\r\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Yes! The best approach is to configure git to use the GitHub CLI credential helper, which will automatically use your existing `gh` authentication:\n",
    "\n",
    "```python\n",
    "!git config --global credential.helper \"\"\n",
    "!git config --global credential.helper 'cache --timeout=3600'\n",
    "!gh auth setup-git\n",
    "```\n",
    "\n",
    "This configures git to use GitHub CLI for authentication. Then try pushing again:\n",
    "\n",
    "```python\n",
    "!git push -u origin main\n",
    "```\n",
    "\n",
    "This way you don't need to manually manage tokens in files or URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de549850",
   "metadata": {
    "time_run": "2025-12-03T06:23:32.787007+00:00"
   },
   "outputs": [],
   "source": [
    "!git config --global credential.helper \"\"\n",
    "!git config --global credential.helper 'cache --timeout=3600'\n",
    "!gh auth setup-git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ec9dd",
   "metadata": {
    "time_run": "2025-12-03T06:24:48.402648+00:00"
   },
   "outputs": [],
   "source": [
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572bd2ad",
   "metadata": {
    "time_run": "2025-11-24T08:25:16.585659+00:00"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import lisette\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ffe61",
   "metadata": {
    "time_run": "2025-11-24T08:25:20.514902+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: Writes and Write-Nots\\n\\nURL Source: https://paulgraham.com/writes.html\\n\\nMarkdown Content:\\n![Im'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog = !curl -s https://r.jina.ai/https://paulgraham.com/writes.html\n",
    "blog = \"\\n\".join(blog)\n",
    "blog[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c8c094",
   "metadata": {
    "time_run": "2025-11-24T08:25:20.556694+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mInit signature:\u001b[39m\n",
       "lisette.Chat(\n",
       "    model: str,\n",
       "    sp=\u001b[33m''\u001b[39m,\n",
       "    temp=\u001b[32m0\u001b[39m,\n",
       "    search=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    tools: list = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    hist: list = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    ns: Optional[dict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    cache=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    cache_idxs: list = [-\u001b[32m1\u001b[39m],\n",
       "    ttl=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       ")\n",
       "\u001b[31mDocstring:\u001b[39m      <no docstring>\n",
       "\u001b[31mInit docstring:\u001b[39m LiteLLM chat client.\n",
       "\u001b[31mFile:\u001b[39m           /usr/local/lib/python3.12/site-packages/lisette/core.py\n",
       "\u001b[31mType:\u001b[39m           type\n",
       "\u001b[31mSubclasses:\u001b[39m     AsyncChat"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lisette.Chat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7375c22f",
   "metadata": {
    "time_run": "2025-11-24T08:25:20.612617+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"\"Lisette Core\"\"\"\\n\\n# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.\\n\\n# %% auto 0\\n_'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = !cat /usr/local/lib/python3.12/site-packages/lisette/core.py \n",
    "code = \"\\n\".join(code)[:len(blog)]\n",
    "code[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b951c12",
   "metadata": {
    "collapsed": true,
    "solveit_ai": true
   },
   "source": [
    "help me write resursive chunking and chunk code and blog, it should make the chunks equal in size, split by \\n then at chars to get something roughly the same size\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Here's a recursive chunker that splits text into roughly equal-sized chunks:\n",
    "\n",
    "```python\n",
    "def chunk_text(text, target_sz=500, split_chars='\\n'):\n",
    "    \"Recursively chunk text into roughly equal sized pieces\"\n",
    "    if len(text) <= target_sz: return [text]\n",
    "    lines = text.split(split_chars)\n",
    "    if len(lines) == 1: return [text[i:i+target_sz] for i in range(0, len(text), target_sz)]\n",
    "    mid = len(lines) // 2\n",
    "    left,right = split_chars.join(lines[:mid]),split_chars.join(lines[mid:])\n",
    "    return chunk_text(left, target_sz, split_chars) + chunk_text(right, target_sz, split_chars)\n",
    "```\n",
    "\n",
    "Now let's chunk both the blog and code:\n",
    "\n",
    "```python\n",
    "blog_chunks = chunk_text(blog, target_sz=500)\n",
    "code_chunks = chunk_text(code, target_sz=500)\n",
    "len(blog_chunks), len(code_chunks)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333eda4",
   "metadata": {
    "time_run": "2025-11-24T08:25:20.654714+00:00"
   },
   "outputs": [],
   "source": [
    "def chunk_text(text, target_sz=500, split_chars='\\n'):\n",
    "    \"Recursively chunk text into roughly equal sized pieces\"\n",
    "    if len(text) <= target_sz: return [text]\n",
    "    lines = text.split(split_chars)\n",
    "    if len(lines) == 1: return [text[i:i+target_sz] for i in range(0, len(text), target_sz)]\n",
    "    mid = len(lines) // 2\n",
    "    left,right = split_chars.join(lines[:mid]),split_chars.join(lines[mid:])\n",
    "    return chunk_text(left, target_sz, split_chars) + chunk_text(right, target_sz, split_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603bc88c",
   "metadata": {
    "time_run": "2025-11-24T08:25:20.701315+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 12)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_chunks = chunk_text(blog, target_sz=500)\n",
    "code_chunks = chunk_text(code, target_sz=500)\n",
    "len(blog_chunks), len(code_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f454d",
   "metadata": {
    "time_run": "2025-11-24T08:25:20.743667+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the strangest things you learn if you're a writer is how many people have trouble writing. Doctors know how many people have a mole they're worried about; people who are good at setting up computers know how many people aren't; writers know how many people need help writing.\n",
      "\n",
      "The reason so many people have trouble writing is that it's fundamentally difficult. To write well you have to think clearly, and thinking clearly is hard.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(blog_chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d12f04",
   "metadata": {
    "time_run": "2025-11-24T08:25:20.792571+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# %% auto 0\n",
      "__all__ = ['sonn45', 'detls_tag', 're_tools', 'effort', 'patch_litellm', 'remove_cache_ckpts', 'mk_msg', 'fmt2hist', 'mk_msgs',\n",
      "           'stream_with_complete', 'lite_mk_func', 'ToolResponse', 'cite_footnote', 'cite_footnotes', 'Chat',\n",
      "           'random_tool_id', 'mk_tc', 'mk_tc_req', 'mk_tc_result', 'mk_tc_results', 'astream_with_complete',\n",
      "           'AsyncChat', 'mk_tr_details', 'AsyncStreamFormatter', 'adisplay_stream']\n"
     ]
    }
   ],
   "source": [
    "print(code_chunks[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79021798",
   "metadata": {},
   "source": [
    "## Make the raw text to tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9252911",
   "metadata": {
    "use_thinking": true
   },
   "source": [
    "let's run knn on the chunks and print them, I think sklearn is not here but torch is. Let's load them to tensors. Load each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abdfd33",
   "metadata": {
    "time_run": "2025-11-24T08:25:25.789801+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.Size([23]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "labels = torch.tensor([0]*len(blog_chunks) + [1]*len(code_chunks))\n",
    "labels[:10], labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15eda3",
   "metadata": {
    "time_run": "2025-11-24T08:25:25.833963+00:00"
   },
   "outputs": [],
   "source": [
    "text_chunks = blog_chunks + code_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462f6d8a",
   "metadata": {
    "time_run": "2025-11-24T08:25:25.875683+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([23, 500]), torch.Size([23]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def as_chars(text_chunks):\n",
    "    \"\"\"Essentially feature 0 value ord('A') means that text starts with 'A' \"\"\"\n",
    "    max_len = max(len(c) for c in text_chunks)\n",
    "    chunks = torch.stack([torch.tensor([ord(ch) for ch in c] + [0]*(max_len-len(c))) for c in text_chunks])\n",
    "    return chunks\n",
    "chunks = as_chars(text_chunks)\n",
    "chunks.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bbff5c",
   "metadata": {
    "collapsed": true,
    "time_run": "2025-11-24T08:25:25.911765+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 84, 105, 116, 108, 101,  58,  32,  87, 114, 105, 116, 101, 115,  32,\n",
       "         97, 110, 100,  32,  87, 114, 105, 116, 101,  45,  78, 111, 116, 115,\n",
       "         10,  10,  85,  82,  76,  32,  83, 111, 117, 114,  99, 101,  58,  32,\n",
       "        104, 116, 116, 112, 115,  58,  47,  47, 112,  97, 117, 108, 103, 114,\n",
       "         97, 104,  97, 109,  46,  99, 111, 109,  47, 119, 114, 105, 116, 101,\n",
       "        115,  46, 104, 116, 109, 108,  10,  10,  77,  97, 114, 107, 100, 111,\n",
       "        119, 110,  32,  67, 111, 110, 116, 101, 110, 116,  58,  10,  33,  91,\n",
       "         73, 109,  97, 103, 101,  32,  49,  58,  32,  87, 114, 105, 116, 101,\n",
       "        115,  32,  97, 110, 100,  32,  87, 114, 105, 116, 101,  45,  78, 111,\n",
       "        116, 115,  93,  40, 104, 116, 116, 112, 115,  58,  47,  47, 115,  46,\n",
       "        116, 117, 114,  98, 105, 102, 121,  99, 100, 110,  46,  99, 111, 109,\n",
       "         47,  97,  97, 104,  47, 112,  97, 117, 108, 103, 114,  97, 104,  97,\n",
       "        109,  47, 119, 114, 105, 116, 101, 115,  45,  97, 110, 100,  45, 119,\n",
       "        114, 105, 116, 101,  45, 110, 111, 116, 115,  45,  49,  46, 103, 105,\n",
       "        102,  41,  79,  99, 116, 111,  98, 101, 114,  32,  50,  48,  50,  52,\n",
       "         10,  73,  39, 109,  32, 117, 115, 117,  97, 108, 108, 121,  32, 114,\n",
       "        101, 108, 117,  99, 116,  97, 110, 116,  32, 116, 111,  32, 109,  97,\n",
       "        107, 101,  32, 112, 114, 101, 100, 105,  99, 116, 105, 111, 110, 115,\n",
       "         32,  97,  98, 111, 117, 116,  32, 116, 101,  99, 104, 110, 111, 108,\n",
       "        111, 103, 121,  44,  32,  98, 117, 116,  32,  73,  32, 102, 101, 101,\n",
       "        108,  32, 102,  97, 105, 114, 108, 121,  32,  99, 111, 110, 102, 105,\n",
       "        100, 101, 110, 116,  32,  97,  98, 111, 117, 116,  32, 116, 104, 105,\n",
       "        115,  32, 111, 110, 101,  58,  32, 105, 110,  32,  97,  32,  99, 111,\n",
       "        117, 112, 108, 101,  32, 100, 101,  99,  97, 100, 101, 115,  32, 116,\n",
       "        104, 101, 114, 101,  32, 119, 111, 110,  39, 116,  32,  98, 101,  32,\n",
       "        109,  97, 110, 121,  32, 112, 101, 111, 112, 108, 101,  32, 119, 104,\n",
       "        111,  32,  99,  97, 110,  32, 119, 114, 105, 116, 101,  46,  10,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b6d48c",
   "metadata": {
    "time_run": "2025-11-24T08:25:25.948674+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Title: Writes and Write-Nots\\n\\nURL Source: https://paulgraham.com/writes.html\\n\\nMarkdown Content:\\n![Image 1: Writes and Write-Nots](https://s.turbifycdn.com/aah/paulgraham/writes-and-write-nots-1.gif)October 2024\\nI'm usually reluctant to make predictions about technology, but I feel fairly confident about this one: in a couple decades there won't be many people who can write.\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(map (chr, chunks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290a3f8",
   "metadata": {},
   "source": [
    "## kNN on raw text chunks - a char at pos - 500 dimensions \n",
    "this essentially random one from feature eng pov. kNN found anticolleration in our case  and is getting 23% acc in balanced set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97b9a8",
   "metadata": {
    "collapsed": true,
    "solveit_ai": true
   },
   "source": [
    "use torch run knn and draw show me visually how it managed to split the chunks\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's run kNN on the raw text chunks and visualize the results:\n",
    "\n",
    "```python\n",
    "def knn_classify(train_x, train_y, test_x, k=3):\n",
    "    \"Simple kNN classifier using L2 distance\"\n",
    "    dists = torch.cdist(test_x.float(), train_x.float())\n",
    "    knn_idx = dists.topk(k, largest=False).indices\n",
    "    knn_labels = train_y[knn_idx]\n",
    "    return knn_labels.float().mean(dim=1).round().long()\n",
    "```\n",
    "\n",
    "Now let's do leave-one-out cross-validation and visualize:\n",
    "\n",
    "```python\n",
    "preds = torch.zeros(len(chunks), dtype=torch.long)\n",
    "for i in range(len(chunks)):\n",
    "    train_idx = torch.cat([torch.arange(i), torch.arange(i+1, len(chunks))])\n",
    "    preds[i] = knn_classify(chunks[train_idx], labels[train_idx], chunks[i:i+1], k=3)\n",
    "\n",
    "acc = (preds == labels).float().mean()\n",
    "print(f'Raw text kNN accuracy: {acc:.2%}')\n",
    "print(f'Predicted: {preds.tolist()}')\n",
    "print(f'Actual:    {labels.tolist()}')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c4189",
   "metadata": {
    "time_run": "2025-11-24T08:25:26.005199+00:00"
   },
   "outputs": [],
   "source": [
    "def knn_classify(train_x, train_y, test_x, k=3):\n",
    "    \"Simple kNN classifier using L2 distance\"\n",
    "    dists = torch.cdist(test_x.float(), train_x.float())\n",
    "    knn_idx = dists.topk(k, largest=False).indices\n",
    "    knn_labels = train_y[knn_idx]\n",
    "    return knn_labels.float().mean(dim=1).round().long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef4965",
   "metadata": {
    "time_run": "2025-11-24T08:25:26.040289+00:00"
   },
   "outputs": [],
   "source": [
    "def show_results(info, preds):\n",
    "    acc = (preds == labels).float().mean()\n",
    "    if acc < 0.5: preds = 1-preds # if kNN miss assigned labels we invert the prediction\n",
    "    acc = (preds == labels).float().mean()\n",
    "    print(f'{info}kNN accuracy: {acc:.2%}')\n",
    "    print(f'Predicted: {preds.tolist()}')\n",
    "    print(f'Actual:    {labels.tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f901ea58",
   "metadata": {
    "collapsed": true,
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "Am I reading the code correctly that the entire set is being used to train? and we only use 3 closest one and use them for voting for 2 clases? if so there is no need for this code right: `if acc < 0.5: preds = 1-preds`.\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ \n",
    "\n",
    "You're reading it correctly. In leave-one-out cross-validation, for each sample we train on all other samples and predict just that one sample using its 3 nearest neighbors for voting.\n",
    "\n",
    "You're also right that the `if acc < 0.5: preds = 1-preds` line isn't needed. The labels are known during training, so kNN will learn the correct mapping. That line would only help if labels were somehow swapped, which doesn't happen here.\n",
    "\n",
    "Let's test it without that line:\n",
    "\n",
    "```python\n",
    "preds = torch.zeros(len(chunks), dtype=torch.long)\n",
    "for i in range(len(chunks)):\n",
    "    train_idx = torch.cat([torch.arange(i), torch.arange(i+1, len(chunks))])\n",
    "    preds[i] = knn_classify(chunks[train_idx], labels[train_idx], chunks[i:i+1], k=3)\n",
    "\n",
    "show_results('Raw text ', preds)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a904ebcd",
   "metadata": {
    "time_run": "2025-11-24T08:25:26.092784+00:00"
   },
   "outputs": [],
   "source": [
    "def show_results(info, preds):\n",
    "    acc = (preds == labels).float().mean()\n",
    "    print(f'{info}kNN accuracy: {acc:.2%}')\n",
    "    print(f'Predicted: {preds.tolist()}')\n",
    "    print(f'Actual:    {labels.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31cab59",
   "metadata": {
    "time_run": "2025-11-24T08:25:26.129981+00:00"
   },
   "outputs": [],
   "source": [
    "def test_knn(name, x):\n",
    "    preds = torch.zeros(len(x), dtype=torch.long)\n",
    "    print('Data dim:',x.shape)\n",
    "    for i in range(len(x)):\n",
    "        train_idx = torch.cat([torch.arange(i), torch.arange(i+1, len(x))])\n",
    "        preds[i] = knn_classify(x[train_idx], labels[train_idx], x[i:i+1], k=3)\n",
    "    show_results(name, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec5be4",
   "metadata": {
    "time_run": "2025-11-24T08:25:26.231915+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 500])\n",
      "Raw text kNN accuracy: 26.09%\n",
      "Predicted: [0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "test_knn('Raw text ', as_chars(text_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c61a7",
   "metadata": {},
   "source": [
    "## kNN on tokens - still meaning less\n",
    "Smaller dim but still random, as we treat cat features as values that have meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3325e8a3",
   "metadata": {
    "collapsed": true,
    "solveit_ai": true
   },
   "source": [
    "Instead of words let's use tiktok tokenize it like for gpt-5 and use it.\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's tokenize the chunks using tiktoken and run kNN on the token representations:\n",
    "\n",
    "```python\n",
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "token_chunks = [enc.encode(c) for c in text_chunks]\n",
    "max_tok_len = max(len(t) for t in token_chunks)\n",
    "tok_tensors = torch.stack([torch.tensor(t + [0]*(max_tok_len-len(t))) for t in token_chunks])\n",
    "tok_tensors.shape\n",
    "```\n",
    "\n",
    "Now run kNN on the tokenized chunks:\n",
    "\n",
    "```python\n",
    "preds = torch.zeros(len(tok_tensors), dtype=torch.long)\n",
    "for i in range(len(tok_tensors)):\n",
    "    train_idx = torch.cat([torch.arange(i), torch.arange(i+1, len(tok_tensors))])\n",
    "    preds[i] = knn_classify(tok_tensors[train_idx], labels[train_idx], tok_tensors[i:i+1], k=3)\n",
    "\n",
    "show_results('tokenized ', preds)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1031844e",
   "metadata": {
    "time_run": "2025-11-24T08:25:50.278952+00:00"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.encoding_for_model(\"gpt-5\")\n",
    "def as_tokens(text_chunks):\n",
    "    token_chunks = [enc.encode(c) for c in text_chunks]\n",
    "    max_tok_len = max(len(t) for t in token_chunks)\n",
    "    tok_tensors = torch.stack([torch.tensor(t + [0]*(max_tok_len-len(t))) for t in token_chunks])\n",
    "    return tok_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376bdbcc",
   "metadata": {
    "time_run": "2025-11-24T08:25:26.812665+00:00"
   },
   "outputs": [],
   "source": [
    "toks = as_tokens(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac23864",
   "metadata": {
    "time_run": "2025-11-24T08:25:51.273602+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Title: Writes and Write-Nots\\n\\nURL Source: https://paulgraham.com/writes.html\\n\\nMarkdown Content:\\n![Image 1: Writes and Write-Nots](https://s.turbifycdn.com/aah/paulgraham/writes-and-write-nots-1.gif)October 2024\\nI'm usually reluctant to make predictions about technology, but I feel fairly confident about this one: in a couple decades there won't be many people who can write.\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(toks[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5fa9c",
   "metadata": {
    "time_run": "2025-11-24T08:25:53.229155+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 135])\n",
      "Raw tokens kNN accuracy: 52.17%\n",
      "Predicted: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "test_knn('Raw tokens ', as_tokens(text_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2efae0",
   "metadata": {},
   "source": [
    "## on Tokens by as Bag of Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a5cf29",
   "metadata": {
    "collapsed": true,
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "ok lets make a proper bag of tokens, and lets make 1 hot vector. Use as_tokens, to get the list of tokens. Make it accept k param if 0 vocab is full, if k > 0 vocab is limited to top k tokens. minimize code use torch not list and Counter\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ \n",
    "\n",
    "```python\n",
    "def bag_of_tokens(text_chunks, k=0):\n",
    "    toks = as_tokens(text_chunks)\n",
    "    flat = toks.flatten()\n",
    "    flat = flat[flat != 0]\n",
    "    if k > 0:\n",
    "        counts = torch.bincount(flat)\n",
    "        vocab = counts.topk(k).indices\n",
    "    else: vocab = flat.unique()\n",
    "    bow = torch.zeros(len(text_chunks), len(vocab))\n",
    "    for i,chunk_toks in enumerate(toks):\n",
    "        chunk_toks = chunk_toks[chunk_toks != 0]\n",
    "        for tok in chunk_toks:\n",
    "            if tok in vocab: bow[i, (vocab == tok).nonzero()] = 1\n",
    "    return bow\n",
    "\n",
    "test_knn('Bag of tokens ', bag_of_tokens(text_chunks))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b7952a",
   "metadata": {
    "time_run": "2025-11-24T08:25:54.556224+00:00"
   },
   "outputs": [],
   "source": [
    "def as_bag_of_tokens(text_chunks, k=0):\n",
    "    toks = as_tokens(text_chunks)\n",
    "    flat = toks.flatten()\n",
    "    flat = flat[flat != 0]\n",
    "    if k > 0:\n",
    "        counts = torch.bincount(flat)\n",
    "        vocab = counts.topk(k).indices\n",
    "    else: vocab = flat.unique()\n",
    "    bow = torch.zeros(len(text_chunks), len(vocab))\n",
    "    for i,chunk_toks in enumerate(toks):\n",
    "        chunk_toks = chunk_toks[chunk_toks != 0]\n",
    "        for tok in chunk_toks:\n",
    "            if tok in vocab: bow[i, (vocab == tok).nonzero()] = 1\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7c546",
   "metadata": {
    "time_run": "2025-11-24T08:25:55.664284+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 686])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of tokens kNN accuracy: 69.57%\n",
      "Predicted: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "test_knn('Bag of tokens ', as_bag_of_tokens(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c89c9",
   "metadata": {
    "time_run": "2025-11-24T08:25:56.120850+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 300])\n",
      "Bag of tokens topk=300 kNN accuracy: 73.91%\n",
      "Predicted: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "test_knn('Bag of tokens topk=300 ', as_bag_of_tokens(text_chunks, k=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47170fd5",
   "metadata": {
    "time_run": "2025-11-24T08:26:00.504959+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 100])\n",
      "Bag of tokens topk=100 kNN accuracy: 91.30%\n",
      "Predicted: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "test_knn('Bag of tokens topk=100 ', as_bag_of_tokens(text_chunks, k=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc30cbf",
   "metadata": {
    "time_run": "2025-11-24T08:26:00.577313+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 50])\n",
      "Bag of tokens topk=50 kNN accuracy: 95.65%\n",
      "Predicted: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "test_knn('Bag of tokens topk=50 ', as_bag_of_tokens(text_chunks, k=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfab9a3",
   "metadata": {
    "time_run": "2025-11-24T08:26:00.636779+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 10])\n",
      "Bag of tokens topk=10 kNN accuracy: 78.26%\n",
      "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "test_knn('Bag of tokens topk=10 ', as_bag_of_tokens(text_chunks, k=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4504d2b3",
   "metadata": {},
   "source": [
    "## kNN on Embeddings - 3072 dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d09581",
   "metadata": {
    "collapsed": true,
    "hide_input": true,
    "solveit_ai": true
   },
   "source": [
    "let's use openai/text-embedding-3-large, here is how to get the embedding the API key is in env from openai import OpenAI\n",
    "```\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=\"<OPENROUTER_API_KEY>\",\n",
    ")\n",
    "\n",
    "embedding = client.embeddings.create(\n",
    "  extra_headers={\n",
    "    \"HTTP-Referer\": \"<YOUR_SITE_URL>\", # Optional. Site URL for rankings on openrouter.ai.\n",
    "    \"X-Title\": \"<YOUR_SITE_NAME>\", # Optional. Site title for rankings on openrouter.ai.\n",
    "  },\n",
    "  model=\"openai/text-embedding-3-large\",\n",
    "  input=\"Your text string goes here\",\n",
    "  # input: [\"text1\", \"text2\", \"text3\"] # batch embeddings also supported!\n",
    "  encoding_format=\"float\"\n",
    ")\n",
    "print(embedding.data[0].embedding)```\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Let's get embeddings for all chunks:\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.environ.get(\"OPENROUTER_API_KEY\"))\n",
    "\n",
    "def get_embeddings(texts):\n",
    "    \"Get embeddings for a list of texts\"\n",
    "    resp = client.embeddings.create(model=\"openai/text-embedding-3-large\", input=texts, encoding_format=\"float\")\n",
    "    return torch.tensor([d.embedding for d in resp.data])\n",
    "\n",
    "text_chunks = blog_chunks + code_chunks\n",
    "embeds = get_embeddings(text_chunks)\n",
    "embeds.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09397927",
   "metadata": {
    "time_run": "2025-11-24T08:26:00.694291+00:00"
   },
   "outputs": [],
   "source": [
    "client = OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=os.environ['OPENROUTER_API_KEY'])\n",
    "def as_embeddings(texts):\n",
    "    \"Get embeddings for a list of texts\"\n",
    "    resp = client.embeddings.create(model=\"openai/text-embedding-3-large\", input=texts, encoding_format=\"float\")\n",
    "    return torch.tensor([d.embedding for d in resp.data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f88ecd9",
   "metadata": {
    "time_run": "2025-11-24T08:26:02.419739+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 3072])\n",
      "Embedings kNN accuracy: 100.00%\n",
      "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "test_knn('Embedings ', as_embeddings(text_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c87e14d",
   "metadata": {},
   "source": [
    "# Jeremy insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ab3e27",
   "metadata": {},
   "source": [
    "**Jeremy inital message that we are exploring here**:\n",
    "> BTW IMO the \"curse of dimensionality\" is greatly over-stated in most textbooks ðŸ™‚ . k-NN actually can work great in high dims. \n",
    "\n",
    "**Jeremy comment about the notebook**:\n",
    "> Iâ€™m not sure itâ€™s showing the impact of dimensionality. Embeddings bring in a whole lot of additional knowledge. Instead, I think you should do a random projection of your high dimensional space. That would test purely dimensionality impact afaict (relying on the Johnsonâ€“Lindenstrauss lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9535fbe",
   "metadata": {},
   "source": [
    "The JL lemma is nuts, stay tuned, I'll explain later but first let's untangle what Jeremy is saying."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c22b04d",
   "metadata": {},
   "source": [
    "I had to use Gemini 3.0 to untangle what Jeremy means, Sonnet in solveit, got completely confused (see the section below). In principle he is right. Gemini has a brilliant example:\n",
    "\n",
    "> **The \"Usain Bolt with a Backpack\" Fallacy**\n",
    "\n",
    "> Your initial experiment compared:\n",
    "> - **A:**Â Bag of Words (Low Dimension, Low Intelligence)\n",
    "> - **B:**Â Embeddings (High Dimension, High Intelligence)\n",
    "\n",
    "> You found thatÂ **B**Â won. You concluded:Â _\"High dimensions aren't a problem.\"_\n",
    "> **Jeremyâ€™s Counter-point:**Â Imagine we want to test ifÂ **wearing a heavy backpack**Â (High Dimensions) slows a runner down.\n",
    "\n",
    "> - You take a random person off the street (Bag of Words), give them no backpack, and time them. They run 100m in 15 seconds.\n",
    "> - You takeÂ **Usain Bolt**Â (Embeddings), give him a heavy backpack, and time him. He runs 100m in 9.8 seconds.\n",
    "\n",
    "> **Conclusion:**Â Usain Bolt with a backpack is faster than a normal person without one.Â **The Fallacy:**Â This doesn't prove the backpack didn't slow him down! Maybe without the backpack, he would have run it in 9.5 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1baf47",
   "metadata": {},
   "source": [
    "That's a fair point, although we got 100% accuracy - the speed of light in the Usain Bolt analogy.\n",
    "So he couldn't go any faster which kind of proves that the backpack / dims don't really matter. \n",
    "\n",
    "But if we had a larger set of examples we could easily go below 100% and then we couldn't tell if the embeddings work despite the high dimensionality or *because of it*.\n",
    "\n",
    "**So let's experiment!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6209ed",
   "metadata": {},
   "source": [
    "### Why JL lemma is nuts - and how crazy the curse looks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f38162",
   "metadata": {},
   "source": [
    "JL lemma says that multiplying our samples by a random matrix so that we get less info preserves distances! Here are the mathy details for the curious, copied from a textbook:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d002d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Johnsonâ€“Lindenstrauss lemma</summary>\n",
    "Lemma from source to Wikipedia article [cims.nyu.edu OBDA_spring16 random_projections.pdf](https://cims.nyu.edu/~cfgranda/pages/OBDA_spring16/material/random_projections.pdf)\n",
    "**Lemma 2.6 (Johnsonâ€“Lindenstrauss lemma)**\n",
    "\n",
    "Let \\(S := \\{x_1, \\ldots, x_k\\} \\subset \\mathbb{R}^n\\).\n",
    "There exists a random function \\(f\\) such that for any pair of points \\(x_i, x_j\\),\n",
    "\n",
    "$$(1 - \\epsilon)\\,\\|x_i - x_j\\|_2^2\n",
    "\\;\\le\\;\n",
    "\\| f(x_i) - f(x_j) \\|_2^2\n",
    "\\;\\le\\;\n",
    "(1 + \\epsilon)\\,\\|x_i - x_j\\|_2^2,$$\n",
    "\n",
    "with probability at least \\(\\tfrac{1}{k}\\) as long as\n",
    "\n",
    "$$m \\;\\ge\\; \\frac{8 \\log(k)}{\\epsilon^2}.$$\n",
    "\n",
    "The random function is of the form\n",
    "\n",
    "$$f(x) := \\frac{1}{\\sqrt{m}} A x,$$\n",
    "\n",
    "where \\(A\\) is a matrix with i.i.d. Gaussian entries with zero mean and unit variance.</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d8b231",
   "metadata": {
    "time_run": "2025-11-24T11:05:06.299299+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 100])\n",
      "Random project 686â†’100 kNN accuracy: 86.96%\n",
      "Predicted: [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def to_dim(x, dim):\n",
    "    \"Randomly project x to dim using Johnson-Lindenstrauss\"\n",
    "    n,d = x.shape\n",
    "    A = torch.randn(d, dim) / (dim ** 0.5)\n",
    "    return x @ A\n",
    "torch.manual_seed(42)\n",
    "\n",
    "test_knn('Random project 686â†’100 ', to_dim(as_bag_of_tokens(text_chunks), 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887a7eca",
   "metadata": {
    "time_run": "2025-11-24T10:54:25.182790+00:00"
   },
   "source": [
    "Wow **87%** and our 686-dimensional bag of tokens had struggled to get 70%. \n",
    "\n",
    "**â€¼ï¸ Multiplying by a random matrix improved accuracy â€¼ï¸** - as long as the number of dimensions is lower! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf86557",
   "metadata": {},
   "source": [
    "That is why people believed in the high dimensional curse for so long. It is very hard to notice what else is being done here despite lowering dimensions!\n",
    "\n",
    "Now we know that the noise is being cancelled out, and the noise was the problem in the first place.\n",
    "\n",
    "Need proof? Let's reverse the experiment and add some dimensions through the random projection. We don't lose the information that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3418ef",
   "metadata": {
    "time_run": "2025-11-24T11:05:07.990146+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 10000])\n",
      "Random project 686â†’10â†’10 000kNN accuracy: 86.96%\n",
      "Predicted: [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "bow_100 = to_dim(as_bag_of_tokens(text_chunks), 100)\n",
    "bow_10k = to_dim(bow_100, 10_000)\n",
    "test_knn('Random project 686â†’10â†’10 000', bow_10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d062a1",
   "metadata": {},
   "source": [
    "Same accuracy!? But that must be due to the number of zeros in the BoW, right?\n",
    "\n",
    "Not reallyâ€”the random projection removed all zeros from the data. See:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9497304f",
   "metadata": {
    "time_run": "2025-11-24T11:42:26.700322+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros: tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5488, -0.1893,  0.1792,  ..., -0.6738,  0.0130, -0.9571],\n",
       "        [ 0.2857,  0.1350,  1.0932,  ..., -1.9826,  0.3779, -0.3724],\n",
       "        [ 0.2880, -0.2351,  0.3067,  ..., -0.3664, -0.3811, -0.0661],\n",
       "        ...,\n",
       "        [-0.0632, -0.7773, -0.8766,  ...,  0.2146,  0.0364,  0.8132],\n",
       "        [ 0.0734, -0.1667, -0.8720,  ..., -0.3027,  1.2025, -0.0971],\n",
       "        [-0.7255, -0.2649,  0.6957,  ...,  0.0587,  0.1213,  0.0872]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of zeros:\",(bow_100==0).sum())\n",
    "bow_100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c6014",
   "metadata": {},
   "source": [
    "But to be sure let's try this with embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebfd187",
   "metadata": {
    "time_run": "2025-11-24T11:11:04.222656+00:00"
   },
   "outputs": [],
   "source": [
    "embeds = as_embeddings(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d773c9b",
   "metadata": {
    "time_run": "2025-11-24T11:43:05.008158+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 10000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings Projected (3072->10_000) kNN accuracy: 100.00%\n",
      "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "test_knn('Embeddings Projected (3072->10_000) ', to_dim(embeds, 10_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27462bf9",
   "metadata": {},
   "source": [
    "This clearly shows that the number of dimension does change the preformance of kNN alone, and the embedding does not work despite large number of dimensions it works **because of it**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7abbd23",
   "metadata": {
    "time_run": "2025-11-24T11:19:11.914770+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 15])\n",
      "Embeddings Projected (3072->15) kNN accuracy: 95.65%\n",
      "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "test_knn('Embeddings Projected (3072->15) ', to_dim(embeds, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4be47e",
   "metadata": {
    "time_run": "2025-11-24T11:19:03.813258+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 50])\n",
      "Embeddings Projected (3072->50) kNN accuracy: 91.30%\n",
      "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6536550376942973625) # I wasn't get a drop in accuracy until 15 dims with seed 42\n",
    "test_knn('Embeddings Projected (3072->50) ', to_dim(embeds, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4476042d",
   "metadata": {},
   "source": [
    "\n",
    ">[!note]\n",
    "> These embeddings are super robust with seed(42). I wasn't able to get a drop in accuracy above 15 dimensions. But with a different seed or at lower dimensions we clearly see the drop in accuracy of embeddings. \n",
    "\n",
    "This clearly shows that the issue is the noise. But to prove it let's do a final test and add some random data to our vectors. Let's say 30 dims on 3k embedding - 1%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02db2e7",
   "metadata": {
    "time_run": "2025-11-24T11:25:13.785763+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 3102])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings + 30 random dims kNN accuracy: 47.83%\n",
      "Predicted: [1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def add_noise(x, dim):\n",
    "    \"Add random noise dimensions to x\"\n",
    "    noise = torch.randn(x.shape[0], dim)\n",
    "    return torch.cat([x, noise], dim=1)\n",
    "torch.manual_seed(42)\n",
    "test_knn('Embeddings + 30 random dims ', add_noise(embeds, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c5ab90",
   "metadata": {
    "time_run": "2025-11-24T11:24:48.590485+00:00"
   },
   "source": [
    "So with just 1% noise our kNN stopped working completely. Accuracy of 50% is essentially random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c5574e",
   "metadata": {
    "skipped": true
   },
   "source": [
    "# Confused Sonnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6051e5db",
   "metadata": {
    "skipped": true
   },
   "source": [
    "## Wikipedia on Curse of High Dim\n",
    "<details>\n",
    "The **curse of dimensionality** refers to various phenomena that arise when analyzing and organizing data in [high-dimensional spaces](https://en.wikipedia.org/wiki/High-dimensional_space \"High-dimensional space\") that do not occur in low-dimensional settings such as the [three-dimensional](https://en.wikipedia.org/wiki/Three-dimensional_space \"Three-dimensional space\")[physical space](https://en.wikipedia.org/wiki/Physical_space \"Physical space\") of everyday experience. The expression was coined by [Richard E. Bellman](https://en.wikipedia.org/wiki/Richard_E._Bellman \"Richard E. Bellman\") when considering problems in [dynamic programming](https://en.wikipedia.org/wiki/Dynamic_programming \"Dynamic programming\").[[1]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-1)[[2]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-2) The curse generally refers to issues that arise when the number of datapoints is small (in a suitably defined sense) relative to the intrinsic dimension of the data.\n",
    "\n",
    "Dimensionally cursed phenomena occur in domains such as [numerical analysis](https://en.wikipedia.org/wiki/Numerical_analysis \"Numerical analysis\"), [sampling](https://en.wikipedia.org/wiki/Sampling_(statistics) \"Sampling (statistics)\"), [combinatorics](https://en.wikipedia.org/wiki/Combinatorics \"Combinatorics\"), [machine learning](https://en.wikipedia.org/wiki/Machine_learning \"Machine learning\"), [data mining](https://en.wikipedia.org/wiki/Data_mining \"Data mining\") and [databases](https://en.wikipedia.org/wiki/Database \"Database\"). The common theme of these problems is that when the dimensionality increases, the [volume](https://en.wikipedia.org/wiki/Volume \"Volume\") of the space increases so fast that the available data become sparse. In order to obtain a reliable result, the amount of data needed often grows exponentially with the dimensionality. Also, organizing and searching data often relies on detecting areas where objects form groups with similar properties; in high dimensional data, however, all objects appear to be sparse and dissimilar in many ways, which prevents common data organization strategies from being efficient.\n",
    "\n",
    "In some problems, each variable can take one of several discrete values, or the range of possible values is divided to give a finite number of possibilities. Taking the variables together, a huge number of combinations of values must be considered. This effect is also known as the [combinatorial explosion](https://en.wikipedia.org/wiki/Combinatorial_explosion \"Combinatorial explosion\"). Even in the simplest case of ![Image 1: {\\displaystyle d}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e85ff03cbe0c7341af6b982e47e9f90d235c66ab)[binary variables](https://en.wikipedia.org/wiki/Binary_data \"Binary data\"), the number of possible combinations already is ![Image 2: {\\displaystyle 2^{d}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e78df590f3fc81f0201082eaaa6844c145c8bdf3), exponential in the dimensionality. Naively, each additional dimension doubles the effort needed to try all combinations.\n",
    "\n",
    "There is an exponential increase in volume associated with adding extra dimensions to a [mathematical space](https://en.wikipedia.org/wiki/Space_(mathematics) \"Space (mathematics)\"). For example, 10 2= 100 evenly spaced sample points suffice to sample a [unit interval](https://en.wikipedia.org/wiki/Unit_interval \"Unit interval\") (try to visualize a \"1-dimensional\" cube, i.e. a line) with no more than 10âˆ’2 = 0.01 distance between points; an equivalent sampling of a 10-dimensional [unit hypercube](https://en.wikipedia.org/wiki/Unit_hypercube \"Unit hypercube\") with a lattice that has a spacing of 10âˆ’2 = 0.01 between adjacent points would require 10 20 = [(10 2)10] sample points. In general, with a spacing distance of 10âˆ’_n_ the 10-dimensional hypercube appears to be a factor of 10 _n_(10âˆ’1) = [(10 _n_)10/(10 _n_)] \"larger\" than the 1-dimensional hypercube, which is the unit interval. In the above example _n_ = 2: when using a sampling distance of 0.01 the 10-dimensional hypercube appears to be 10 18 \"larger\" than the unit interval. This effect is a combination of the combinatorics problems above and the distance function problems explained below.\n",
    "\n",
    "When solving dynamic [optimization](https://en.wikipedia.org/wiki/Optimization_(mathematics) \"Optimization (mathematics)\") problems by numerical [backward induction](https://en.wikipedia.org/wiki/Backward_induction \"Backward induction\"), the objective function must be computed for each combination of values. This is a significant obstacle when the dimension of the \"state variable\" is large.[[3]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-3)\n",
    "\n",
    "In [machine learning](https://en.wikipedia.org/wiki/Machine_learning \"Machine learning\") problems that involve learning a \"state-of-nature\" from a finite number of data samples in a high-dimensional [feature space](https://en.wikipedia.org/wiki/Feature_space \"Feature space\") with each feature having a range of possible values, typically an enormous amount of training data is required to ensure that there are several samples with each combination of values. In an abstract sense, as the number of features or dimensions grows, the amount of data we need to generalize accurately grows exponentially.[[4]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-4)\n",
    "\n",
    "A typical rule of thumb is that there should be at least 5 training examples for each dimension in the representation.[[5]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-Pattern_recog-5) In [machine learning](https://en.wikipedia.org/wiki/Machine_learning \"Machine learning\") and insofar as predictive performance is concerned, the _curse of dimensionality_ is used interchangeably with the _peaking phenomenon_,[[5]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-Pattern_recog-5) which is also known as _Hughes phenomenon_.[[6]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-6) This phenomenon states that with a fixed number of training samples, the average (expected) predictive power of a classifier or regressor first increases as the number of dimensions or features used is increased but beyond a certain dimensionality it starts deteriorating instead of improving steadily.[[7]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-7)[[8]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-8)[[9]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-McLachlan:2004-9)\n",
    "\n",
    "Nevertheless, in the context of a _simple_ classifier (e.g., [linear discriminant analysis](https://en.wikipedia.org/wiki/Linear_discriminant_analysis \"Linear discriminant analysis\") in the multivariate Gaussian model under the assumption of a common known covariance matrix), Zollanvari, _et al._, showed both analytically and empirically that as long as the relative cumulative efficacy of an additional feature set (with respect to features that are already part of the classifier) is greater (or less) than the size of this additional feature set, the expected error of the classifier constructed using these additional features will be less (or greater) than the expected error of the classifier constructed without them. In other words, both the size of additional features and their (relative) cumulative discriminatory effect are important in observing a decrease or increase in the average predictive power.[[10]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-zollanvari-10)\n",
    "\n",
    "In [metric learning](https://en.wikipedia.org/wiki/Similarity_learning \"Similarity learning\"), higher dimensions can sometimes allow a model to achieve better performance. After normalizing embeddings to the surface of a hypersphere, FaceNet achieves the best performance using 128 dimensions as opposed to 64, 256, or 512 dimensions in one ablation study.[[11]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-11) A loss function for unitary-invariant dissimilarity between word embeddings was found to be minimized in high dimensions.[[12]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-12)\n",
    "\n",
    "Genetic mutations in individuals data set | Individual name | Gene 1 | Gene 2 | ... | Gene 2000 |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Individual 1 | 1 | 0 | ... | 1 |\n",
    "| ... | ... | ... | ... | ... |\n",
    "| Individual 200 | 0 | 1 | ... | 1 |\n",
    "\n",
    "In [data mining](https://en.wikipedia.org/wiki/Data_mining \"Data mining\"), the curse of dimensionality refers to a data set with too many features.\n",
    "\n",
    "Consider the first table, which depicts 200 individuals and 2000 genes (features) with a 1 or 0 denoting whether or not they have a genetic mutation in that gene. A data mining application to this data set may be finding the correlation between specific genetic mutations and creating a classification algorithm such as a [decision tree](https://en.wikipedia.org/wiki/Decision_tree \"Decision tree\") to determine whether an individual has cancer or not.\n",
    "\n",
    "Growth of association pair permutations as pair size grows | Number of pairs | Calculation for permutations | Number of permutations calculated for each row |\n",
    "| --- | --- | --- |\n",
    "| 2 | ![Image 3: {\\displaystyle 2000!/(2000-2)!}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6919bac120998dc9a118c7db6db2290680f6d7eb) | 3 998 000 |\n",
    "| 3 | ![Image 4: {\\displaystyle 2000!/(2000-3)!}](https://wikimedia.org/api/rest_v1/media/math/render/svg/8dd346f2ea647c92b300969f4ef89101b8e06807) | 7 988 004 000 |\n",
    "| 4 | ![Image 5: {\\displaystyle 2000!/(2000-4)!}](https://wikimedia.org/api/rest_v1/media/math/render/svg/43a91339cf75cd19c8c2652c5d0c1f227c0a71da) | 15 952 043 988 000 |\n",
    "| 5 | ![Image 6: {\\displaystyle 2000!/(2000-5)!}](https://wikimedia.org/api/rest_v1/media/math/render/svg/2757f6d06ff55c3203d7ea4d22eec94d6c8787d8) | 31 840 279 800 048 000 |\n",
    "\n",
    "A common practice of data mining in this domain would be to create [association rules](https://en.wikipedia.org/wiki/Association_rules \"Association rules\") between genetic mutations that lead to the development of cancers. To do this, one would have to loop through each genetic mutation of each individual and find other genetic mutations that occur over a desired threshold and create pairs. They would start with pairs of two, then three, then four until they result in an empty set of pairs. The complexity of this algorithm can lead to calculating all permutations of gene pairs for each individual or row. Given the formula for calculating the permutations of n items with a group size of r is: ![Image 7: {\\displaystyle {\\frac {n!}{(n-r)!}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a3815bff4f871b3966ff933b696081a299831549), calculating the number of three pair permutations of any given individual would be 7 988 004 000 different pairs of genes to evaluate for each individual. The number of pairs created will grow by an order of factorial as the size of the pairs increase. The growth is depicted in the permutation table (see right).\n",
    "\n",
    "As we can see from the permutation table above, one of the major problems data miners face regarding the curse of dimensionality is that the space of possible parameter values grows exponentially or factorially as the number of features in the data set grows. This problem critically affects both computational time and space when searching for associations or optimal features to consider.\n",
    "\n",
    "Another problem data miners may face when dealing with too many features is that the number of false predictions or classifications tends to increase as the number of features grows in the data set. In terms of the classification problem discussed above, keeping every data point could lead to a higher number of [false positives and false negatives](https://en.wikipedia.org/wiki/False_positives_and_false_negatives \"False positives and false negatives\") in the model.\n",
    "\n",
    "This may seem counterintuitive, but consider the genetic mutation table from above, depicting all genetic mutations for each individual. Each genetic mutation, whether they correlate with cancer or not, will have some input or weight in the model that guides the decision-making process of the algorithm. There may be mutations that are [outliers](https://en.wikipedia.org/wiki/Outliers \"Outliers\") or ones that dominate the overall distribution of genetic mutations when in fact they do not correlate with cancer. These features may be working against one's model, making it more difficult to obtain optimal results.\n",
    "\n",
    "This problem is up to the data miner to solve, and there is no universal solution. The first step any data miner should take is to explore the data, in an attempt to gain an understanding of how it can be used to solve the problem. One must first understand what the data means, and what they are trying to discover before they can decide if anything must be removed from the data set. Then they can create or use a [feature selection](https://en.wikipedia.org/wiki/Feature_selection \"Feature selection\") or [dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction \"Dimensionality reduction\") algorithm to remove samples or features from the data set if they deem it necessary. One example of such methods is the [interquartile range](https://en.wikipedia.org/wiki/Interquartile_range \"Interquartile range\") method, used to remove [outliers](https://en.wikipedia.org/wiki/Outliers \"Outliers\") in a data set by calculating the standard deviation of a feature or occurrence.\n",
    "\n",
    "When a measure such as a [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance \"Euclidean distance\") is defined using many coordinates, there is little difference in the distances between different pairs of points.\n",
    "\n",
    "One way to illustrate the \"vastness\" of high-dimensional Euclidean space is to compare the proportion of an inscribed [hypersphere](https://en.wikipedia.org/wiki/Hypersphere \"Hypersphere\") with radius ![Image 8: {\\displaystyle r}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0d1ecb613aa2984f0576f70f86650b7c2a132538) and dimension ![Image 9: {\\displaystyle d}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e85ff03cbe0c7341af6b982e47e9f90d235c66ab), to that of a [hypercube](https://en.wikipedia.org/wiki/Hypercube \"Hypercube\") with edges of length ![Image 10: {\\displaystyle 2r.}](https://wikimedia.org/api/rest_v1/media/math/render/svg/f7e9c3fbe39aa463f573b1cbec01883275295ff2) The volume of such a sphere is ![Image 11: {\\displaystyle {\\frac {2r^{d}\\pi ^{d/2}}{d\\;\\Gamma (d/2)}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/34c8e9ef702e36d4b6c3caa01ce2812bdc017b18), where [![Image 12: {\\displaystyle \\Gamma }](https://wikimedia.org/api/rest_v1/media/math/render/svg/4cfde86a3f7ec967af9955d0988592f0693d2b19)](https://en.wikipedia.org/wiki/Gamma_function \"Gamma function\") is the [gamma function](https://en.wikipedia.org/wiki/Gamma_function \"Gamma function\"), while the volume of the cube is ![Image 13: {\\displaystyle (2r)^{d}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e4b70ddaebe60763b3fc154e45d328f835de17f9). As the dimension ![Image 14: {\\displaystyle d}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e85ff03cbe0c7341af6b982e47e9f90d235c66ab) of the space increases, the hypersphere becomes an insignificant volume relative to that of the hypercube. This can clearly be [seen](https://commons.wikimedia.org/wiki/File:Ball-cube-volume-ratio-semilog.png \"commons:File:Ball-cube-volume-ratio-semilog.png\") by comparing the proportions as the dimension ![Image 15: {\\displaystyle d}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e85ff03cbe0c7341af6b982e47e9f90d235c66ab) goes to infinity:\n",
    "\n",
    "![Image 16: {\\displaystyle {\\frac {V_{\\mathrm {hypersphere} }}{V_{\\mathrm {hypercube} }}}={\\frac {\\pi ^{d/2}}{d2^{d-1}\\Gamma (d/2)}}\\rightarrow 0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0b1e17f55f56082ada1da60e44dee2bb1a10495d) as ![Image 17: {\\displaystyle d\\rightarrow \\infty }](https://wikimedia.org/api/rest_v1/media/math/render/svg/bce9ca5152257151f074c2018a2e2f8f504d65f6).\n",
    "Furthermore, the distance between the center and the corners is ![Image 18: {\\displaystyle r{\\sqrt {d}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/7d1e8509527b454d4708c554ef2ab34288cca085), which increases without bound for fixed r.\n",
    "\n",
    "In this sense when points are [uniformly generated](https://en.wikipedia.org/wiki/Continuous_uniform_distribution \"Continuous uniform distribution\") in a high-dimensional hypercube, almost all points are much farther than ![Image 19: {\\displaystyle r}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0d1ecb613aa2984f0576f70f86650b7c2a132538) units away from the center. In high dimensions, the volume of the _d_-dimensional unit hypercube (with coordinates of the vertices ![Image 20: {\\displaystyle \\pm 1}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0bfeaa85da53ad1947d8000926cfea33827ef1e0)) is concentrated near a sphere with the radius ![Image 21: {\\displaystyle {\\sqrt {d}}/{\\sqrt {3}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/3215169b3a7e3aba80fc854897a71df728f07cf0) for large dimension _d_. Indeed, for each coordinate ![Image 22: {\\displaystyle x_{i}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158) the average value of ![Image 23: {\\displaystyle x_{i}^{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0ea4ea44d82d72c37a4f22ba288ffef326f925d4) in the cube is[[13]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-Bailey2006-13)\n",
    "\n",
    "![Image 24: {\\displaystyle \\left\\langle x_{i}^{2}\\right\\rangle ={\\frac {1}{2}}\\int _{-1}^{1}x^{2}dx={\\frac {1}{3}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/92b967d2b42096d412ad0f0bd481192291250442).\n",
    "The variance of ![Image 25: {\\displaystyle x_{i}^{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0ea4ea44d82d72c37a4f22ba288ffef326f925d4) for uniform distribution in the cube is\n",
    "\n",
    "![Image 26: {\\displaystyle {\\frac {1}{2}}\\int _{-1}^{1}x^{4}dx-\\left\\langle x_{i}^{2}\\right\\rangle ^{2}={\\frac {4}{45}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/bb48a5499b810222bb6b211a09552af534a57f63)\n",
    "Therefore, the squared distance from the origin, ![Image 27: {\\textstyle r^{2}=\\sum _{i}x_{i}^{2}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a91a8a16040c7f09d939aaa36193c003323644a5) has the average value _d_/3 and variance 4 _d_/45. For large _d_, distribution of ![Image 28: {\\displaystyle r^{2}/d}](https://wikimedia.org/api/rest_v1/media/math/render/svg/86d46a7da0f9016cbdec0a29e4168f51a1cf0ca5) is close to the [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution \"Normal distribution\") with the mean 1/3 and the standard deviation ![Image 29: {\\displaystyle 2/{\\sqrt {45d}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/0ae7f1180e91bce0ab5d800718e6e35a58d0e01a) according to the [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem \"Central limit theorem\"). Thus, when uniformly generating points in high dimensions, both the \"middle\" of the hypercube, and the corners are empty, and all the volume is concentrated near the surface of a sphere of \"intermediate\" radius ![Image 30: {\\textstyle {\\sqrt {d/3}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/373ee55483ca044ad6ed460bcb087cee106ac7f9).\n",
    "\n",
    "This also helps to understand the [chi-squared distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution \"Chi-squared distribution\"). Indeed, the (non-central) chi-squared distribution associated to a random point in the [interval](https://en.wikipedia.org/wiki/Interval_(mathematics) \"Interval (mathematics)\") [-1, 1] is the same as the distribution of the length-squared of a random point in the _d_-cube. By the law of large numbers, this distribution concentrates itself in a narrow band around _d_ times the standard deviation squared (Ïƒ 2) of the original derivation. This illuminates the chi-squared distribution and also illustrates that most of the volume of the _d_-cube concentrates near the boundary of a sphere of radius ![Image 31: {\\displaystyle \\sigma {\\sqrt {d}}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6865a3b591f15b618aa4b236e6df88676095a134).\n",
    "\n",
    "A further development of this phenomenon is as follows. Any fixed distribution on the [real numbers](https://en.wikipedia.org/wiki/Real_number \"Real number\") induces a product distribution on points in ![Image 32: {\\displaystyle \\mathbb {R} ^{d}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a713426956296f1668fce772df3c60b9dde8a685). For any fixed _n_, it turns out that the difference between the minimum and the maximum distance between a random reference point _Q_ and a list of _n_ random data points _P_ 1,...,_P_ _n_ become indiscernible compared to the minimum distance:[[14]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-14)\n",
    "\n",
    "![Image 33: {\\displaystyle \\lim _{d\\to \\infty }E\\left({\\frac {\\operatorname {dist} _{\\max }(d)-\\operatorname {dist} _{\\min }(d)}{\\operatorname {dist} _{\\min }(d)}}\\right)\\to 0}](https://wikimedia.org/api/rest_v1/media/math/render/svg/b13e3be054e337e51b4e1e37fe8953d03b22a272).\n",
    "This is often cited as distance functions losing their usefulness (for the nearest-neighbor criterion in feature-comparison algorithms, for example) in high dimensions. However, recent research has shown this to only hold in the artificial scenario when the one-dimensional distributions ![Image 34: {\\displaystyle \\mathbb {R} }](https://wikimedia.org/api/rest_v1/media/math/render/svg/786849c765da7a84dbc3cce43e96aad58a5868dc) are [independent and identically distributed](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables \"Independent and identically distributed random variables\").[[15]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-survey-15) When attributes are correlated, data can become easier and provide higher distance contrast and the [signal-to-noise ratio](https://en.wikipedia.org/wiki/Signal-to-noise_ratio \"Signal-to-noise ratio\") was found to play an important role, thus [feature selection](https://en.wikipedia.org/wiki/Feature_selection \"Feature selection\") should be used.[[15]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-survey-15)\n",
    "\n",
    "More recently, it has been suggested that there may be a conceptual flaw in the argument that contrast-loss creates a curse in high dimensions. Machine learning can be understood as the problem of assigning instances to their respective generative process of origin, with class labels acting as symbolic representations of individual generative processes. The curse's derivation assumes all instances are independent, identical outcomes of a single high dimensional generative process. If there is only one generative process, there would exist only one (naturally occurring) class and machine learning would be conceptually ill-defined in both high and low dimensions. Thus, the traditional argument that contrast-loss creates a curse, may be fundamentally inappropriate. In addition, it has been shown that when the generative model is modified to accommodate multiple generative processes, contrast-loss can morph from a curse to a blessing, as it ensures that the nearest-neighbor of an instance is almost-surely its most closely related instance. From this perspective, contrast-loss makes high dimensional distances especially meaningful and not especially non-meaningful as is often argued.[[16]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-16)\n",
    "\n",
    "### Nearest neighbor search\n",
    "\n",
    "[[edit](https://en.wikipedia.org/w/index.php?title=Curse_of_dimensionality&action=edit&section=8 \"Edit section: Nearest neighbor search\")]\n",
    "\n",
    "The effect complicates [nearest neighbor search](https://en.wikipedia.org/wiki/Nearest_neighbor_search \"Nearest neighbor search\") in high dimensional space. It is not possible to quickly reject candidates by using the difference in one coordinate as a lower bound for a distance based on all the dimensions.[[17]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-17)[[18]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-18)\n",
    "\n",
    "However, it has recently been observed that the mere number of dimensions does not necessarily result in difficulties,[[19]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-houle-ssdbm10-19) since _relevant_ additional dimensions can also increase the contrast. In addition, for the resulting ranking it remains useful to discern close and far neighbors. Irrelevant (\"noise\") dimensions, however, reduce the contrast in the manner described above. In [time series analysis](https://en.wikipedia.org/wiki/Time_series_analysis \"Time series analysis\"), where the data are inherently high-dimensional, distance functions also work reliably as long as the [signal-to-noise ratio](https://en.wikipedia.org/wiki/Signal-to-noise_ratio \"Signal-to-noise ratio\") is high enough.[[20]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-houle-sstd11-20)\n",
    "\n",
    "#### _k_-nearest neighbor classification\n",
    "\n",
    "[[edit](https://en.wikipedia.org/w/index.php?title=Curse_of_dimensionality&action=edit&section=9 \"Edit section: k-nearest neighbor classification\")]\n",
    "\n",
    "Another effect of high dimensionality on distance functions concerns _k_-nearest neighbor (_k_-NN) [graphs](https://en.wikipedia.org/wiki/Graph_(discrete_mathematics) \"Graph (discrete mathematics)\") constructed from a [data set](https://en.wikipedia.org/wiki/Data_set \"Data set\") using a distance function. As the dimension increases, the [indegree](https://en.wikipedia.org/wiki/Indegree \"Indegree\") distribution of the _k_-NN [digraph](https://en.wikipedia.org/wiki/Directed_graph \"Directed graph\") becomes [skewed](https://en.wikipedia.org/wiki/Skewness \"Skewness\") with a peak on the right because of the emergence of a disproportionate number of **hubs**, that is, data-points that appear in many more _k_-NN lists of other data-points than the average.[[21]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-21) This phenomenon can have a considerable impact on various techniques for [classification](https://en.wikipedia.org/wiki/Classification_(machine_learning) \"Classification (machine learning)\") (including the [_k_-NN classifier](https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm \"K-nearest neighbor algorithm\")), [semi-supervised learning](https://en.wikipedia.org/wiki/Semi-supervised_learning \"Semi-supervised learning\"), and [clustering](https://en.wikipedia.org/wiki/Cluster_analysis \"Cluster analysis\"),[[22]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-22) and it also affects [information retrieval](https://en.wikipedia.org/wiki/Information_retrieval \"Information retrieval\").[[23]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-23)\n",
    "\n",
    "In a 2012 survey, Zimek et al. identified the following problems when searching for [anomalies](https://en.wikipedia.org/wiki/Anomaly_detection \"Anomaly detection\") in high-dimensional data:[[15]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-survey-15)\n",
    "\n",
    "1.   Concentration of scores and distances: derived values such as distances become numerically similar\n",
    "2.   Irrelevant attributes: in high dimensional data, a significant number of attributes may be irrelevant\n",
    "3.   Definition of reference sets: for local methods, reference sets are often nearest-neighbor based\n",
    "4.   Incomparable scores for different dimensionalities: different subspaces produce incomparable scores\n",
    "5.   Interpretability of scores: the scores often no longer convey a semantic meaning\n",
    "6.   Exponential search space: the search space can no longer be systematically scanned\n",
    "7.   [Data snooping](https://en.wikipedia.org/wiki/Data_snooping \"Data snooping\") bias: given the large search space, for every desired significance a hypothesis can be found\n",
    "8.   Hubness: certain objects occur more frequently in neighbor lists than others.\n",
    "\n",
    "Many of the analyzed specialized methods tackle one or another of these problems, but there remain many open research questions.\n",
    "\n",
    "### Blessing of dimensionality\n",
    "\n",
    "[[edit](https://en.wikipedia.org/w/index.php?title=Curse_of_dimensionality&action=edit&section=11 \"Edit section: Blessing of dimensionality\")]\n",
    "\n",
    "Despite the expected \"curse of dimensionality\" difficulties, common-sense heuristics based on the most straightforward methods \"can yield results which are almost surely optimal\" for high-dimensional problems.[[24]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-Kainen1997-24) The term \"blessing of dimensionality\" was introduced in the late 1990s.[[24]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-Kainen1997-24)[Donoho](https://en.wikipedia.org/wiki/David_Donoho \"David Donoho\") in his \"Millennium manifesto\" explained why he thinks the \"blessing of dimensionality\" will form a basis of future data mining.[[25]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-Donoho2000-25) The effects of the blessing of dimensionality were discovered in many applications and found their foundation in the [concentration of measure phenomena](https://en.wikipedia.org/wiki/Concentration_of_measure \"Concentration of measure\").[[26]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-GorbanEntr2020-26) One example of the blessing of dimensionality phenomenon is linear separability of a random point from a large finite random set with high probability even if this set is exponentially large: the number of elements in this random set can grow exponentially with dimension. Moreover, this linear functional can be selected in the form of the simplest linear [Fisher discriminant](https://en.wikipedia.org/wiki/Linear_discriminant_analysis \"Linear discriminant analysis\"). This separability theorem was proven for a wide class of probability distributions: general uniformly log-concave distributions, product distributions in a cube and many other families (reviewed recently in [[26]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-GorbanEntr2020-26)).\n",
    "\n",
    "\"The blessing of dimensionality and the curse of dimensionality are two sides of the same coin.\"[[27]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-GorTyukPhTranRS2018-27) For example, the typical property of essentially high-dimensional probability distributions in a high-dimensional space is: the squared distance of random points to a selected point is, with high probability, close to the average (or median) squared distance. This property significantly simplifies the expected geometry of data and indexing of high-dimensional data (blessing),[[28]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-Hecht1994-28) but, at the same time, it makes the similarity search in high dimensions difficult and even useless (curse).[[29]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-PestovCamwa2013-29)\n",
    "\n",
    "Zimek et al.[[15]](https://en.wikipedia.org/wiki/Curse_of_dimensionality#cite_note-survey-15) noted that while the typical formalizations of the curse of dimensionality affect [i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables \"Independent and identically distributed random variables\") data, having data that is separated in each attribute becomes easier even in high dimensions, and argued that the [signal-to-noise ratio](https://en.wikipedia.org/wiki/Signal-to-noise_ratio \"Signal-to-noise ratio\") matters: data becomes easier with each attribute that adds signal, and harder with attributes that only add noise (irrelevant error) to the data. In particular for unsupervised data analysis this effect is known as swamping.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d47bb2c",
   "metadata": {
    "skipped": true,
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "It appears I don't know the curse at all. Could you bring the theorem / lemma, quote wiki. Also, show me the difference of what you are saying with bag of tokens experiments. It clearly shows drop in accuracy when form  50, top tokens we go to 200 and then 300.\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ \n",
    "\n",
    "From the Wikipedia article you shared, here's the key quote about distances in high dimensions:\n",
    "\n",
    "> \"In addition, for the resulting ranking it remains useful to discern close and far neighbors. Irrelevant ('noise') dimensions, however, reduce the contrast in the manner described above.\"\n",
    "\n",
    "And more directly:\n",
    "\n",
    "> \"Zimek et al. noted that while the typical formalizations of the curse of dimensionality affect i.i.d. data, having data that is separated in each attribute becomes easier even in high dimensions, and argued that the signal-to-noise ratio matters: data becomes easier with each attribute that adds signal, and harder with attributes that only add noise (irrelevant error) to the data.\"\n",
    "\n",
    "Your bag-of-tokens experiment actually **demonstrates** this perfectly! When you go from top-50 to top-300 tokens, you're not just adding dimensions - you're adding **noise dimensions**. The top 50 tokens are the most frequent and likely most discriminative between blog posts and code. The tokens ranked 51-300 are rarer and probably appear in both types of text, adding noise rather than signal.\n",
    "\n",
    "In contrast, embeddings have 3072 dimensions but each dimension encodes **meaningful semantic information** learned from vast amounts of text. These aren't random or noisy dimensions.\n",
    "\n",
    "Does that help clarify the distinction between \"high dimensionality with noise\" vs \"high dimensionality with signal\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2d03c3",
   "metadata": {
    "skipped": true,
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "Ok so what jeremy means in his last commnet?\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ \n",
    "\n",
    "Jeremy's pointing out that your current experiment conflates two things:\n",
    "\n",
    "1. **Dimensionality** (how many features)\n",
    "2. **Learned knowledge** (embeddings contain semantic understanding from pre-training)\n",
    "\n",
    "He's suggesting that to test whether high dimensions *alone* cause problems for kNN, you should use **random projection** instead of embeddings. Random projection would take your high-dimensional bag-of-words and project it to a different dimensional space using a random matrix - preserving distances but without adding any learned semantic knowledge.\n",
    "\n",
    "The **Johnson-Lindenstrauss lemma** says that points in high dimensions can be projected into lower dimensions (via random projection) while approximately preserving distances between points. So if kNN works on randomly projected high-dimensional data, it shows the curse of dimensionality isn't the real problem - it's about signal vs noise.\n",
    "\n",
    "Would you like to try implementing a random projection experiment to test this? Or would you like me to explain the Johnson-Lindenstrauss lemma more first?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74884003",
   "metadata": {
    "skipped": true,
    "solveit_ai": true
   },
   "source": [
    "Give me the lamma. Does it work in both directions? So If i project something with low dimension in to high dimensions I get the distances preserved?\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "The **Johnson-Lindenstrauss lemma** states:\n",
    "\n",
    "For any set of *n* points in high-dimensional space and any Îµ > 0, there exists a mapping into k-dimensional space (where k = O(log n / ÎµÂ²)) such that all pairwise distances are preserved within a factor of (1 Â± Îµ).\n",
    "\n",
    "More formally: for any two points u, v:\n",
    "(1 - Îµ)||u - v||Â² â‰¤ ||f(u) - f(v)||Â² â‰¤ (1 + Îµ)||u - v||Â²\n",
    "\n",
    "**Direction matters!** The lemma is specifically about projecting from *high* to *lower* dimensions. It doesn't work in reverse - you can't take low-dimensional data, project it to high dimensions with a random matrix, and expect meaningful distance preservation. That would just add random noise.\n",
    "\n",
    "The key insight: high-dimensional data often lies on or near a lower-dimensional manifold, so you can compress it without losing the essential distance structure.\n",
    "\n",
    "Does this clarify why random projection would be a good test for Jeremy's point?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd8bb7",
   "metadata": {
    "skipped": true
   },
   "source": [
    "Lemma from source to Wikipedia article [cims.nyu.edu OBDA_spring16 random_projections.pdf](https://cims.nyu.edu/~cfgranda/pages/OBDA_spring16/material/random_projections.pdf)\n",
    "**Lemma 2.6 (Johnsonâ€“Lindenstrauss lemma)**\n",
    "\n",
    "Let \\(S := \\{x_1, \\ldots, x_k\\} \\subset \\mathbb{R}^n\\).\n",
    "There exists a random function \\(f\\) such that for any pair of points \\(x_i, x_j\\),\n",
    "\n",
    "$$(1 - \\epsilon)\\,\\|x_i - x_j\\|_2^2\n",
    "\\;\\le\\;\n",
    "\\| f(x_i) - f(x_j) \\|_2^2\n",
    "\\;\\le\\;\n",
    "(1 + \\epsilon)\\,\\|x_i - x_j\\|_2^2,$$\n",
    "\n",
    "with probability at least \\(\\tfrac{1}{k}\\) as long as\n",
    "\n",
    "$$m \\;\\ge\\; \\frac{8 \\log(k)}{\\epsilon^2}.$$\n",
    "\n",
    "The random function is of the form\n",
    "\n",
    "$$f(x) := \\frac{1}{\\sqrt{m}} A x,$$\n",
    "\n",
    "where \\(A\\) is a matrix with i.i.d. Gaussian entries with zero mean and unit variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b520dd6e",
   "metadata": {
    "skipped": true,
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "So he means to take my full bag of tokens with 686 dims and squash it in to lower dim and observe that the accuracy does not changes?\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ \n",
    "\n",
    "Actually, I think Jeremy means the opposite! He's suggesting you take a *good* representation (like your 50-dim bag with 95.65% accuracy) and randomly project it to *higher* dimensions. \n",
    "\n",
    "If kNN still works well in the higher-dimensional random projection, it would show that high dimensionality *itself* isn't the problem - it's whether the dimensions contain signal or noise.\n",
    "\n",
    "Your 686-dim full bag has lots of rare tokens (noise). A random projection would add dimensions but in a way that preserves the distance structure without adding the kind of noise that rare tokens do.\n",
    "\n",
    "Which experiment sounds more interesting to you:\n",
    "1. Random project 50-dim â†’ 1000-dim and see if accuracy stays high?\n",
    "2. Random project 686-dim â†’ 100-dim and see if it improves?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc3b8a",
   "metadata": {
    "skipped": true,
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "But you said that the direction matters, and I can't project low dim to high dim and keep the distances? Or do I read the lemma wrong?\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ \n",
    "\n",
    "You're absolutely right to question me - I contradicted myself! \n",
    "\n",
    "The lemma says you can project from **high to lower** dimensions while preserving distances. It doesn't work in reverse.\n",
    "\n",
    "So I was wrong to suggest projecting 50-dim â†’ 1000-dim. That doesn't align with the lemma.\n",
    "\n",
    "Re-reading Jeremy's comment, I think he means: take your 686-dim bag-of-words (with poor 69.57% accuracy) and randomly project it DOWN to, say, 100 dimensions. Then compare:\n",
    "- 686-dim â†’ random project to 100-dim \n",
    "- vs your top-100 tokens (which selects specific dimensions)\n",
    "\n",
    "If random projection works better than keeping all 686 dims, it suggests high dimensionality itself is a problem. If it performs similarly to top-100 token selection, it suggests dimension selection (signal vs noise) matters more than raw dimensionality.\n",
    "\n",
    "Does that interpretation make more sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab266481",
   "metadata": {
    "skipped": true,
    "solveit_ai": true
   },
   "source": [
    "Make the relevant code and let's see\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "```python\n",
    "def random_project(x, target_dim):\n",
    "    \"Randomly project x to target_dim using Johnson-Lindenstrauss\"\n",
    "    n,d = x.shape\n",
    "    A = torch.randn(d, target_dim) / (target_dim ** 0.5)\n",
    "    return x @ A\n",
    "\n",
    "test_knn('Random project 686â†’100 ', random_project(as_bag_of_tokens(text_chunks), 100))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c10d1",
   "metadata": {
    "skipped": true,
    "time_run": "2025-11-24T08:55:51.553811+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 100])\n",
      "Random project 686â†’100 kNN accuracy: 82.61%\n",
      "Predicted: [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def lower_dim(x, dim):\n",
    "    \"Randomly project x to dim using Johnson-Lindenstrauss\"\n",
    "    n,d = x.shape\n",
    "    A = torch.randn(d, dim) / (dim ** 0.5)\n",
    "    return x @ A\n",
    "\n",
    "test_knn('Random project 686â†’100 ', lower_dim(as_bag_of_tokens(text_chunks), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b1bc93",
   "metadata": {
    "skipped": true,
    "time_run": "2025-11-24T08:57:23.081175+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 50])\n",
      "686->50 kNN accuracy: 86.96%\n",
      "Predicted: [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Data dim: torch.Size([23, 50])\n",
      "300->50 kNN accuracy: 78.26%\n",
      "Predicted: [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Data dim: torch.Size([23, 50])\n",
      "100->50 kNN accuracy: 100.00%\n",
      "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "test_knn('686->50 ', lower_dim(as_bag_of_tokens(text_chunks), 50))\n",
    "test_knn('300->50 ', lower_dim(as_bag_of_tokens(text_chunks, k=300), 50))\n",
    "test_knn('100->50 ', lower_dim(as_bag_of_tokens(text_chunks, k=100), 50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2fbce3",
   "metadata": {
    "skipped": true,
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "Wow I'm lost it actually helped, the full bag of tokens lowering to 50 dims somehow improved the accuracy. Help me understand this, how it works. Course says that in high dim data is close to all points, keeping the distances and lowering the dim should not help then !\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ \n",
    "\n",
    "Great observation! Here's what's happening:\n",
    "\n",
    "The curse of dimensionality says distances become meaningless when you have many **irrelevant/noisy** dimensions. Your 686-dim bag has ~600 rare tokens that are essentially noise.\n",
    "\n",
    "Random projection works because of what the JL lemma *really* tells us: **if distances can be preserved in lower dimensions, then the meaningful distance structure was already in a lower-dimensional subspace!**\n",
    "\n",
    "When you randomly project 686â†’50, you're:\n",
    "1. Combining features randomly (each new dim is a weighted combo of old dims)\n",
    "2. This averages out the noise from rare tokens\n",
    "3. While preserving the signal that separates blog from code\n",
    "\n",
    "Think of it like this: the useful information in your 686 dims was \"compressed\" into maybe 50-100 meaningful directions. The other 586+ dimensions were just noise making distances harder to interpret.\n",
    "\n",
    "Notice:\n",
    "- 686 dims (all tokens): 69.57%\n",
    "- Random 686â†’50: 86.96% (better! noise reduced)\n",
    "- Top-50 selected: 95.65% (best! deliberate selection)\n",
    "- Random 100â†’50: 100% (starting with less noise helps even more)\n",
    "\n",
    "So Jeremy's right: high dimensionality *per se* isn't the curse - it's high dimensionality filled with **noise**. Random projection reveals this by preserving the signal while dampening noise.\n",
    "\n",
    "Make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ef14df",
   "metadata": {
    "skipped": true,
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "What in the above proofs that the high dimensionality pr se isn't the curse? \n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ \n",
    "\n",
    "You're right to push back! Looking at the experiments again:\n",
    "\n",
    "- 686 dims â†’ 69.57%\n",
    "- 686â†’50 random projection â†’ 86.96%\n",
    "\n",
    "This actually shows that **reducing** dimensions improved accuracy, which seems to support the curse of dimensionality!\n",
    "\n",
    "The real proof that \"high dimensionality per se isn't the curse\" is actually your **embeddings result**:\n",
    "\n",
    "- Embeddings: **3072 dimensions â†’ 100%** accuracy\n",
    "\n",
    "That's the key! You went from 686 noisy dimensions with poor performance to 3072 learned dimensions with perfect performance. If high dimensionality itself was the problem, 3072 dims should be worse than 686 dims. But it's not - it's perfect.\n",
    "\n",
    "So the complete picture is:\n",
    "- 686 dims of noise (rare tokens): 69.57%\n",
    "- 3072 dims of signal (learned embeddings): 100%\n",
    "\n",
    "**That** proves it's not about the number of dimensions - it's about whether those dimensions contain meaningful signal or just noise.\n",
    "\n",
    "The random projection experiments show something different: that the noisy 686 dims contain some compressible signal, but that's a separate observation.\n",
    "\n",
    "Does this clarify the actual proof?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ded9c5",
   "metadata": {
    "skipped": true,
    "solveit_ai": true
   },
   "source": [
    "Why Jeremy thinks i'm conflating ideas?\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Jeremy thinks you're conflating two separate effects:\n",
    "\n",
    "1. **High dimensionality itself** (the geometric curse - distances becoming similar)\n",
    "2. **What embeddings bring** (semantic knowledge learned from billions of tokens)\n",
    "\n",
    "Your experiment compared:\n",
    "- Raw/bag-of-words features (no learned knowledge)\n",
    "- vs Embeddings (massive learned knowledge)\n",
    "\n",
    "When embeddings work better, you can't tell if it's because:\n",
    "- They handle high dimensions better? OR\n",
    "- They contain vastly more semantic information?\n",
    "\n",
    "Jeremy's suggesting: use random projection on your bag-of-words to test dimensionality effects **without** adding learned knowledge. That would isolate whether high dimensions alone are problematic.\n",
    "\n",
    "But actually, your results so far show something interesting:\n",
    "- 686 noisy dims: 69.57%\n",
    "- 686â†’50 random projection: 86.96%\n",
    "- 3072 embedding dims: 100%\n",
    "\n",
    "This suggests dimensionality reduction helps when you have noise, but embeddings work despite being even higher dimensional - supporting Jeremy's point that it's about signal quality, not dimension count.\n",
    "\n",
    "Does that clarify what he means by conflating?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da95af63",
   "metadata": {},
   "source": [
    "## At this point I handed the whole dialog to Gemini 3.0. \n",
    "\n",
    "It got the meaning of Jeremie's suggestion perfectly, providing me with analogy that cleard things up. And suggested some experiments that actually showed the point that the Embedding works because of it high dim not despite of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13918f9",
   "metadata": {},
   "source": [
    "## Gemini opinion\n",
    "\n",
    "Attached kNN_high_dim.md\n",
    ">Help me understand Jeremies point. AI in this conversation is very confused. Here is the relevant Jeremies comment:\n",
    ">\\*\\*Jeremy inital message that we are exploring here\\*\\*:\n",
    "> \\> BTW IMO the \"curse of dimensionality\" is greatly over-stated in most textbooks ðŸ™‚. k-NN actually can work great in high dims.\n",
    "> \\*\\*Jeremy comment about the notebook\\*\\*:\n",
    "> \\> Iâ€™m not sure itâ€™s showing the impact of dimensionality. Embeddings bring in a whole lot of additional knowledge. Instead, I think you should do a random projection of your high dimensional space. That would test purely dimensionality impact afaict (relying on the Johnsonâ€“Lindenstrauss lemma)\n",
    "\n",
    "---\n",
    "\n",
    "Here is the explanation of Jeremyâ€™s point, untangling the confusion from the previous turn.\n",
    "\n",
    "### 1\\. What \"Conflating\" means here\n",
    "\n",
    "Jeremy is saying your experiment is unfair because you changed two variables at once:\n",
    "\n",
    "1. **Dimensionality:** (Low in BoW vs. High in Embeddings)\n",
    "2. **Intelligence/Information:** (Dumb word counts vs. Smart semantic vectors trained on the whole internet)\n",
    "\n",
    "When `Embeddings (3072 dim)` beat `Bag of Words (686 dim)`, you concluded: \"High dimensions are fine!\" Jeremy argues: \"No, you just proved that **GPT-4 is smarter than counting words**.\"\n",
    "\n",
    "To test the **Curse of Dimensionality** (and nothing else), you must keep the **information constant** and only change the **dimensions**.\n",
    "\n",
    "### 2\\. The JL Lemma (The \"Shadow\" Analogy)\n",
    "\n",
    "The Johnson-Lindenstrauss (JL) lemma is the mathematical key here. Think of it like a shadow:\n",
    "\n",
    "- **The Object:** Your data in High Dimensions.\n",
    "- **The Shadow:** Your data projected (squashed) onto the floor (Low Dimensions).\n",
    "\n",
    "The Lemma proves that if you cast a shadow mathematically (using a random matrix), **the distances between points in the shadow stay proportional to the distances between the real objects.**\n",
    "\n",
    "**Jeremy's Logic:**If you can project 3,000 dimensions down to 50 dimensions and the kNN accuracy **stays the same**, it proves that the **geometry was never broken in 3,000 dimensions**. The distances were already good; the extra dimensions weren't \"cursing\" the data, they were just there.\n",
    "\n",
    "### 3\\. Why the previous AI got confused\n",
    "\n",
    "The previous AI was confused by your BoW results:\n",
    "\n",
    "- *BoW (686 dims)*: ~70%\n",
    "- *BoW Projected (50 dims)*: ~87%\n",
    "\n",
    "The AI thought: \"See? Lower dimensions are better! The Curse is real!\"\n",
    "\n",
    "**But here is the nuance:**Bag of Words is **Sparse** (mostly zeros). In BoW, high dimensionality introduces **Noise** (rare words that appear once). Projecting BoW down helped because it \"smoothed out\" the noise (denoising), not just because it reduced dimensions.\n",
    "\n",
    "### 4\\. The Correct Experiment (What Jeremy wants)\n",
    "\n",
    "To prove Jeremy's point (\"The curse is overstated; kNN works fine in high dims\"), you should use the **Embeddings** (which we know are high quality) and project them down.\n",
    "\n",
    "- **Step 1:** Take Embeddings (3072 dims) Accuracy is 100%.\n",
    "- **Step 2:** Randomly project them to 50 dims.\n",
    "- **Step 3:** Run kNN.\n",
    "\n",
    "**Prediction:** If the accuracy stays at (or near) 100%, you have proved that **3072 dimensions were not a curse.** The distance metric worked perfectly fine in 3072 dimensions, and it works perfectly fine in 50.\n",
    "\n",
    "If the \"Curse\" were true as textbooks say, the 3072-dim version should have failed or been much worse than the 50-dim version.\n",
    "\n",
    "---\n",
    "\n",
    "### Actionable Code\n",
    "\n",
    "Let's run the **Random Projection on the Embeddings** (High Signal, High Dim) rather than the Bag of Words (Low Signal, High Noise).\n",
    "\n",
    "Python\n",
    "\n",
    "```python\n",
    "# We use the 'lower_dim' function you already defined, which implements JL projection\n",
    "\n",
    "# 1. Baseline: High Dimensional Embeddings (3072 dims)\n",
    "# We expect 100%\n",
    "test_knn('Embeddings (3072 dims) ', embeds) \n",
    "\n",
    "# 2. Experiment: Random Projection to Low Dimensions (50 dims)\n",
    "# If Jeremy is right, this should ALSO be ~100%. \n",
    "# This proves the distance structure was preserved from high to low.\n",
    "embeds_projected = lower_dim(embeds, 50)\n",
    "test_knn('Embeddings Projected (3072->50) ', embeds_projected)\n",
    "```\n",
    "\n",
    "**Would you like me to run this comparison to finally settle the debate?**\n",
    "\n",
    "---\n",
    "\n",
    "> Wow, ok that's is something:\n",
    "```python\n",
    "Output: 540\n",
    "Data dim: torch.Size([23, 3072])\n",
    "Embeddings (3072 dims) kNN accuracy: 100.00%\n",
    "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "Actual: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "Data dim: torch.Size([23, 50])\n",
    "Embeddings Projected (3072->50) kNN accuracy: 91.30%\n",
    "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1]\n",
    "Actual: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "```\n",
    "---\n",
    "\n",
    "This result is the **smoking gun** that proves Jeremy's point.\n",
    "\n",
    "Here is the breakdown of why this result settles the debate:\n",
    "\n",
    "### 1\\. The \"Textbook\" Expectation vs. Reality\n",
    "\n",
    "- **The \"Curse\" Hypothesis:** If the Curse of Dimensionality were the dominant factor, the distance metric should break down in 3,072 dimensions. You would expect the 3,072-dim version to be **worse** (or at least no better) than the 50-dim version.\n",
    "- **Your Result:**\n",
    "\t- **3,072 Dimensions:** 100% Accuracy (Perfect)\n",
    "\t- **50 Dimensions:** 91.30% Accuracy (Worse)\n",
    "\n",
    "**Conclusion:** The high dimensionality was **not a curse**. In fact, the full high-dimensional space contained the *most* accurate geometric information.\n",
    "\n",
    "### 2\\. Why did the accuracy drop to 91%?\n",
    "\n",
    "The drop from 100% 91% is exactly what the **Johnson-Lindenstrauss (JL) Lemma** predicts.\n",
    "\n",
    "- The lemma says random projections preserve distances *approximately*.\n",
    "- When you squash 3,000 dimensions into 50, you lose some fidelity (like saving a high-res image as a small thumbnail).\n",
    "- The fact that it *only* dropped to 91% shows that the **geometry of the embeddings is incredibly robust**. Even a jagged, random shadow of the data is enough to separate \"Code\" from \"Blog\" almost perfectly.\n",
    "\n",
    "### 3\\. The Final Synthesis (Signal vs. Noise)\n",
    "\n",
    "This allows us to draw the complete picture of your experiments:\n",
    "\n",
    "| Feature Set | Dimensions | Result | Why? |\n",
    "| --- | --- | --- | --- |\n",
    "| **Bag of Words** | 686 | **Poor (70%)** | **High Noise.** Most dims are rare words that confuse the distance metric. |\n",
    "| **BoW Projected** | 50 | **Better (87%)** | **Denoising.** Projection averaged out the sparse noise. |\n",
    "| **Embeddings** | 3,072 | **Perfect (100%)** | **High Signal.** These dimensions aren't random; they encode meaning. |\n",
    "| **Embeddings Projected** | 50 | **Great (91%)** | **Compression.** Good signal survives compression, but full resolution is best. |\n",
    "\n",
    "### 4\\. Visualizing the \"Blessing\"\n",
    "\n",
    "To see the JL Lemma in action, you can run this loop. You will likely see the accuracy climb from ~91% back up to 100% as you give the projection a little more \"breathing room\" (e.g., 100 or 200 dims).\n",
    "\n",
    "Python\n",
    "\n",
    "```python\n",
    "# Test how many dimensions we actually need to hit 100%\n",
    "for k in [10, 50, 100, 200, 500]:\n",
    "    proj = lower_dim(embeds, k)\n",
    "    print(f\"Testing projection to {k} dims...\")\n",
    "    test_knn(f'Embeddings -> {k} dims ', proj)\n",
    "    print(\"-\" * 30)\n",
    "```\n",
    "\n",
    "**Summary:** Jeremy was right. In the era of Deep Learning, high dimensionality is often a **blessing** (richer information) rather than a curse, provided your features are good (like embeddings) rather than sparse/noisy (like raw word counts)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a32ca",
   "metadata": {},
   "source": [
    "## Experiments suggested by Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97e432e",
   "metadata": {
    "skipped": true,
    "time_run": "2025-11-24T11:10:09.118443+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 3072])\n",
      "Embeddings (3072 dims) kNN accuracy: 100.00%\n",
      "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Data dim: torch.Size([23, 50])\n",
      "Embeddings Projected (3072->50) kNN accuracy: 86.96%\n",
      "Predicted: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "embeds = as_embeddings(text_chunks)\n",
    "# We use the 'lower_dim' function you already defined, which implements JL projection\n",
    "\n",
    "# 1. Baseline: High Dimensional Embeddings (3072 dims)\n",
    "# We expect 100%\n",
    "test_knn('Embeddings (3072 dims) ', embeds) \n",
    "\n",
    "# 2. Experiment: Random Projection to Low Dimensions (50 dims)\n",
    "# If Jeremy is right, this should ALSO be ~100%. \n",
    "# This proves the distance structure was preserved from high to low.\n",
    "embeds_projected = lower_dim(embeds, 50)\n",
    "test_knn('Embeddings Projected (3072->50) ', embeds_projected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33505ff4",
   "metadata": {
    "skipped": true
   },
   "source": [
    "The results are not that stable due to the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450dac3c",
   "metadata": {
    "skipped": true,
    "time_run": "2025-11-24T09:40:56.518636+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 3072])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings (3072 dims) kNN accuracy: 100.00%\n",
      "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Data dim: torch.Size([23, 50])\n",
      "Embeddings Projected (3072->50) kNN accuracy: 95.65%\n",
      "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# We use the 'lower_dim' function you already defined, which implements JL projection\n",
    "\n",
    "# 1. Baseline: High Dimensional Embeddings (3072 dims)\n",
    "# We expect 100%\n",
    "test_knn('Embeddings (3072 dims) ', embeds) \n",
    "\n",
    "# 2. Experiment: Random Projection to Low Dimensions (50 dims)\n",
    "# If Jeremy is right, this should ALSO be ~100%. \n",
    "# This proves the distance structure was preserved from high to low.\n",
    "embeds_projected = lower_dim(embeds, 50)\n",
    "test_knn('Embeddings Projected (3072->50) ', embeds_projected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15afc7f5",
   "metadata": {
    "skipped": true,
    "time_run": "2025-11-24T09:41:01.878639+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dim: torch.Size([23, 3072])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings (3072 dims) kNN accuracy: 100.00%\n",
      "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Data dim: torch.Size([23, 50])\n",
      "Embeddings Projected (3072->50) kNN accuracy: 91.30%\n",
      "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# We use the 'lower_dim' function you already defined, which implements JL projection\n",
    "\n",
    "# 1. Baseline: High Dimensional Embeddings (3072 dims)\n",
    "# We expect 100%\n",
    "test_knn('Embeddings (3072 dims) ', embeds) \n",
    "\n",
    "# 2. Experiment: Random Projection to Low Dimensions (50 dims)\n",
    "# If Jeremy is right, this should ALSO be ~100%. \n",
    "# This proves the distance structure was preserved from high to low.\n",
    "embeds_projected = lower_dim(embeds, 50)\n",
    "test_knn('Embeddings Projected (3072->50) ', embeds_projected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7187e862",
   "metadata": {
    "skipped": true,
    "time_run": "2025-11-24T10:09:21.649865+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (50 dims):\n",
      "Data dim: torch.Size([23, 50])\n",
      "BoW (50 dims) kNN accuracy: 95.65%\n",
      "Predicted: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "------------------------------\n",
      "Experiment (Projected UP to 10,000 dims):\n",
      "Data dim: torch.Size([23, 10000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW (50 -> 10,000 dims) kNN accuracy: 95.65%\n",
      "Predicted: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def project_up(x, target_dim):\n",
    "    \"Project x UP to target_dim using a random matrix\"\n",
    "    n, d = x.shape\n",
    "    # We create a random matrix of shape (d, target_dim)\n",
    "    # This maps 50 inputs to 10000 outputs\n",
    "    A = torch.randn(d, target_dim) \n",
    "    return x @ A\n",
    "\n",
    "# 1. Get our baseline \"Good\" Low-Dim Data (BoW projected to 50)\n",
    "bow_50 = as_bag_of_tokens(text_chunks, k=50)\n",
    "print(\"Baseline (50 dims):\")\n",
    "test_knn('BoW (50 dims) ', bow_50)\n",
    "\n",
    "# 2. Project it UP to 10,000 dimensions\n",
    "# We are putting the same data into a massive empty room.\n",
    "bow_10k = project_up(bow_50, 10000)\n",
    "print(\"-\" * 30)\n",
    "print(\"Experiment (Projected UP to 10,000 dims):\")\n",
    "test_knn('BoW (50 -> 10,000 dims) ', bow_10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d1c893",
   "metadata": {
    "skipped": true
   },
   "source": [
    "But BoW is mostly 0, let see what will happen with an embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fef352",
   "metadata": {
    "skipped": true,
    "time_run": "2025-11-24T11:08:49.149687+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (50 dims):\n",
      "Data dim: torch.Size([23, 50])\n",
      "Embeds (50 dims) kNN accuracy: 100.00%\n",
      "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "------------------------------\n",
      "Experiment (Projected UP to 10,000 dims):\n",
      "Data dim: torch.Size([23, 10000])\n",
      "Embeds (50 -> 10,000 dims) kNN accuracy: 100.00%\n",
      "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 1. Get our baseline \"Good\" Low-Dim Data (BoW projected to 50)\n",
    "embeds_50 = lower_dim(embeds, 50)\n",
    "print(\"Baseline (50 dims):\")\n",
    "test_knn('Embeds (50 dims) ', embeds_50)\n",
    "\n",
    "# 2. Project it UP to 10,000 dimensions\n",
    "# We are putting the same data into a massive empty room.\n",
    "embeds_10k = project_up(embeds_50, 10_000)\n",
    "print(\"-\" * 30)\n",
    "print(\"Experiment (Projected UP to 10,000 dims):\")\n",
    "test_knn('Embeds (50 -> 10,000 dims) ', embeds_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aca27f",
   "metadata": {
    "skipped": true,
    "time_run": "2025-11-24T11:08:39.457382+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Experiment (Projected UP to 10,000 dims):\n",
      "Data dim: torch.Size([23, 10000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeds (50 -> 10,000 dims) kNN accuracy: 100.00%\n",
      "Predicted: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Actual:    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedsf_10k = project_up(embeds, 10_000)\n",
    "print(\"-\" * 30)\n",
    "print(\"Experiment (Projected UP to 10,000 dims):\")\n",
    "test_knn('Embeds (50 -> 10,000 dims) ', embedsf_10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beead0e6",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "I have created a repo name \"knn_dimension\"\r\n",
    "\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great! Now let's initialize git in your current directory and push to that repository:\n",
    "\n",
    "```python\n",
    "!git init\n",
    "!git add .\n",
    "!git commit -m \"Initial commit: kNN dimensionality experiments\"\n",
    "!git branch -M main\n",
    "!git remote add origin https://github.com/niminet/knn_dimension.git\n",
    "!git push -u origin main\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c24a07",
   "metadata": {
    "time_run": "2025-12-03T06:10:17.724231+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitialized existing Git repository in /app/data/.git/\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master (root-commit) fea2748] Initial commit: kNN dimensionality experiments\r\n",
      " 7 files changed, 2656 insertions(+)\r\n",
      " create mode 100644 .bash_history\r\n",
      " create mode 100644 .config/gh/config.yml\r\n",
      " create mode 100644 .config/gh/hosts.yml\r\n",
      " create mode 100644 .gitconfig\r\n",
      " create mode 100644 .ipython/profile_default/startup/README\r\n",
      " create mode 100644 kNN_high_dim.ipynb\r\n",
      " create mode 100644 solveit_settings.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Repository not found.\r\n",
      "fatal: repository 'https://github.com/niminet/knn_dimension.git/' not found\r\n"
     ]
    }
   ],
   "source": [
    "!git init\n",
    "!git add .\n",
    "!git commit -m \"Initial commit: kNN dimensionality experiments\"\n",
    "!git branch -M main\n",
    "!git remote add origin https://github.com/niminet/knn_dimension.git\n",
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c522bc",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "How to fix this\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "The repository doesn't exist on GitHub yet. Let's create it using the GitHub CLI:\n",
    "\n",
    "```python\n",
    "!gh repo create knn_dimension --public --source=. --remote=origin\n",
    "```\n",
    "\n",
    "Then push:\n",
    "\n",
    "```python\n",
    "!git push -u origin main\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a7a04a",
   "metadata": {
    "time_run": "2025-12-03T06:12:21.478171+00:00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphQL: Resource not accessible by personal access token (createRepository)\r\n"
     ]
    }
   ],
   "source": [
    "!gh repo create knn_dimension --public --source=. --remote=origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c3db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git push -u origin main"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "concise",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
